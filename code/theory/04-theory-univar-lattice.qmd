## Global Measures

Global methods give us an overview over the entire field-of-view and summarize spatial autocorrelation metrics to a single value. The metrics are a function of the weight matrix and the variables of interest. The variables of interest can be gene expression, intensity of a marker or the area of the cell. The global measures can be seen as a weighted average of the local metric, as explained below.

In general, a global spatial autocorrelation measure has the form of a double sum over all locations $i,j$

$$\sum_i \sum_j f(x_i,x_j) w_{ij}$$

where $f(x_i,x_j)$ is the measure of association between features of interest and $w_{ij}$ scales the relationship by a spatial weight as defined in the weight matrix $W$. If $i$ and $j$ are not neighbours, i.e. we assume they do not have any spatial association, the corresponding element of the weight matrix is $0$ (i.e., $w_{ij} = 0$). Below we will see that the function $f$ varies between the different spatial autocorrelation measures [@zuurAnalysingEcologicalData2007; @pebesmaSpatialDataScience2023; @anselin2024introduction].

### Global Moran's $I$ coefficient

The global Moran's $I$ [@moranNotesContinuousStochastic1950] coefficient is a measure of spatial autocorrelation, defined as:

$$I = \frac{n}{\sum_i\sum_j w_{ij}} \frac{\sum_i\sum_j w_{ij}(x_i - \bar{x})(x_j - \bar{x})}{\sum_i (x_i - \bar{x})^2}.$$

where $x_i$ and $x_j$ represent the values of the variable of interest at locations $i$ and $j$, $\bar{x}$ is the mean of all $x$ and $w_{ij}$ is the spatial weight between the locations of $i$ and $j$. The expected value is close to $0$ for large $n$ ($\mathbb{E}(I) = -1/(n-1)$), whereas a value higher than this expectation indicates spatial autocorrelation. Negative values indicate negative autocorrelation. Moran's $I$ can be interpreted as the Pearson correlation between the value at location $i$ and the average value of the neigbours of $i$, (neighbours as defined in the weight matrix $W$) [@moranNotesContinuousStochastic1950; @pebesmaAppliedSpatialDataAnalysis2013, pp. 258-261; @cliff1981spatial, p. 21].

::: {.panel-tabset}

### `R`

```{r}
resMoran <- calculateMoransI(
  sfe,
  features = features,
  colGraphName = colGraphName,
  exprs_values = "logcounts"
)
```

We can also use the `moran.mc` function to calculate the Moran's $I$ coefficient. This function uses a Monte Carlo simulation to calculate the p-value.

```{r}
sfe <- runUnivariate(sfe,
                     features = features,
                     colGraphName = colGraphName,
                     exprs_values = "logcounts",
                     type = "moran.mc",
                     nsim = 200)

res <- rowData(sfe)[features,]
res
```

### `Python`

```{python}
for feature in features:
    moran = Moran(adata[:, feature].X.toarray().astype(np.float64), spatial_weights, transformation="r", permutations=100)
    adata.uns[f"moran_{feature}"] = moran.I
    adata.uns[f"moran_{feature}_p_sim"] = moran.p_sim

for key in filter(lambda x: x.startswith("moran_"), adata.uns.keys()):
    print(f"{key}: {adata.uns[key].round(4)}")
```

:::

The result of global Moran's $I$ for the gene `r features[[1]]` is `r round(resMoran$moran[1], digits = 3)`, the associated p-values is `r round(res[[paste0('moran.mc_p.value_', unique(sfe$sample_id))]][1], digits = 3)`. This means that gene `r features[[1]]` shows `r if(resMoran$moran[1]>0){'positive autocorrelation'}else{'negative autocorrelation'}`

The result of global Moran's $I$ for the gene `r features[[2]]` is `r round(resMoran$moran[2], digits = 3)`, the associated p-values is `r round(res[[paste0('moran.mc_p.value_', unique(sfe$sample_id))]][2], digits = 3)`. This means that gene `r features[[2]]` shows `r if(resMoran$moran[2]>0){'positive autocorrelation'}else{'negative autocorrelation'}`

One should note that the result is dependent on the weight matrix. Different weight matrices will give different results. To compare Moran's $I$ coefficients of different features, we need to use the same weight matrix.

### Global's Geary's $C$ coefficient

Geary's $C$ [@gearyContiguityRatioStatistical1954] is a different measure of global autocorrelation and is very closely related to Moran's $I$. However, it focuses on spatial dissimilarity rather than similarity. Geary's $C$ is defined by

$$C = \frac{(n-1) \sum_i \sum_j w_{ij}(x_i-x_j)^2}{2\sum_i \sum_j w_{ij}\sum_i(x_i-\bar{x})^2}$$

where $x_i$ and $x_j$ represent the values of the variable of interest at locations $i$ and $j$, $\bar{x}$ is the mean of all $x$, $w_{ij}$ is the spatial weight between the locations of $i$ and $j$ and $n$ the total number of locations. The interpretation is opposite to Moran's $I$: a value smaller than $1$ indicates positive autocorrelation whereas a value greater than $1$ represents negative autocorrelation [@cliff1981spatial, p. 17; @pebesmaSpatialDataScience2023; @fischer2010handbook, pp. 255-265].

::: {.panel-tabset}

#### `R`

```{r}
sfe <- runUnivariate(sfe,
                     features = features,
                     colGraphName = colGraphName,
                     nsim = 200,
                     type = "geary.mc")

res <- rowData(sfe)[features,]
res
```

#### `Python`

```{python}
for feature in features:
    geary = Geary(adata[:, feature].X.toarray().astype(np.float64), spatial_weights, transformation="r", permutations=100)
    adata.uns[f"geary_{feature}"] = geary.C
    adata.uns[f"geary_{feature}_p_sim"] = geary.p_sim

for key in filter(lambda x: x.startswith("geary_"), adata.uns.keys()):
    print(f"{key}: {adata.uns[key].round(4)}")
```

:::

The result of global Geary's $C$ for the gene `r features[[1]]` is `r round(res[[paste0('geary.mc_statistic_', unique(sfe$sample_id))]][1], digits = 3)`, the associated p-values is `r round(res[[paste0('geary.mc_p.value_', unique(sfe$sample_id))]][1], digits = 3)`. This means that gene `r features[[1]]` shows `r if(res[[paste0('geary.mc_statistic_', unique(sfe$sample_id))]][1]<1){'positive autocorrelation'}else{'negative autocorrelation'}`

The result of global Geary's $C$ for the gene `r features[[2]]` is `r round(res[[paste0('geary.mc_statistic_', unique(sfe$sample_id))]][2], digits = 3)`, the associated p-values is `r round(res[[paste0('geary.mc_p.value_', unique(sfe$sample_id))]][2], digits = 3)`. This means that gene `r features[[2]]` shows `r if(res[[paste0('geary.mc_statistic_', unique(sfe$sample_id))]][2]<1){'positive autocorrelation'}else{'negative autocorrelation'}`

### Global Getis-Ord $G$ statistic

The global $G$ [@getisAnalysisSpatialAssociation1992] statistic is a generalisation of the local version (see below) and summarises the contributions of all pairs of values $(x_i, x_j)$ in the dataset. Formally that is

$$G(d) = \frac{\sum_{i = 1}^n \sum_{j=1}^n w_{ij}(d)x_ix_j}{\sum_{i = 1}^n \sum_{j=1}^n x_i x_j} \text{s.t } j \neq i.$$

The interpretation works by calculating a $z$-statistic to compare the observed with the expected $G(d)$ statistic. If this value is positive, we refer to this as a hot spot and if it is negative as a cold spot [@getisAnalysisSpatialAssociation1992;@anselin2024introduction].

The global $G(d)$ statistic is very similar to global Moran's $I$. The global $G(d)$ statistic is based on the sum of the products of the data points whereas global Moran's $I$ is based on the sum of the covariances. Since these two approaches capture different aspects of a structure, their values will differ as well. A good approach would be to not use one statistic in isolation but rather consider both [@getisAnalysisSpatialAssociation1992].

This framework was established for binary weights but can be extended to nonbinary weights as well [@ordLocalSpatialAutocorrelation1995]. We will use the `spdep` package directly to calculate the global $G$ statistic.

::: {.panel-tabset}

#### `R`

```{r}
# Get the weight matrix from sfe object
weights_neighbourhoods_binary <- colGraph(sfe, 'binary')
# Change it to binary weights
weights_neighbourhoods_binary$style <- "B" 
# Calculate the global G statistic
res <- spdep::globalG.test(x = logcounts(sfe)[features[1],], 
                    listw = weights_neighbourhoods_binary)
res 
```

#### `Python`

```{python}
for feature in features:
    getisord = G(adata[:, feature].X.toarray(), spatial_weights, permutations=0)
    print("Global G statistic", feature, getisord.z_norm)
    print("Global G statistic (raw)", feature, getisord.G)
    print("Global G statistic (expected)", feature, getisord.EG)
    print("p_norm", feature, getisord.p_norm)
```

:::

The result of global Getis-Ord $G$ for the gene `r features[[1]]` is `r round(res$estimate[[1]], digits = 5)`, the $z$-statistic is `r round(res$statistic[[1]], digits = 5)` the associated $p$-values is `r res$p.value[[1]]`. This means that gene `r features[[1]]` shows `r if(res$statistic[[1]]>0){'a hot spot'}else{'a cold spot'}`

## Local measures

Unlike global measures that give an overview over the entire field of view, local measures report information about the statistic at each location (cell). There exist local analogs of Moran's $I$ and Geary's $C$ for which the global statistic can be represented as a weighted sum of the local statistics. As above, the local coefficients are based on both the spatial weights matrix and the values of the measurement of interest [@anselinLocalIndicatorsSpatial1995].

### Local Moran's $I$ coefficient

The local Moran's $I$ coefficient [@anselinLocalIndicatorsSpatial1995] is a measure of spatial autocorrelation at each location of interest. It is defined as:

$$I_i = \frac{x_i - \bar{x}}{\sum_{k=1}^n(x_k-\bar{x})^2/(n-1)} \sum_{j=1}^n w_{ij}(x_j - \bar{x})$$

where the index $i$ refers to the location for which the measure is calculated. The interpretation is analogous to the global Moran's $I$ where a value of $I_i$ higher than $\mathbb{E}(I_i) = -w_i/(n-1)$ indicates spatial autocorrelation; smaller values indicate negative autocorrelation [@anselinLocalIndicatorsSpatial1995]. It is important to note that, as for the global counterpart, the value of local Moran's $I$ could be a result from both the high or low end of the values. Since we measure and test a large number of locations simultaneously, we need to correct for multiple testing (e.g., using the Benjamini-Hochberg procedure [@benjamini_hochberg1995fdr]) [@pebesmaSpatialDataScience2023].

::: {.panel-tabset}

#### `R`

```{r}
#| fig-width: 15
#| fig-height: 10

sfe <- runUnivariate(sfe,
                     features = features,
                     colGraphName = colGraphName,
                     type = "localmoran")

plotLocalResult(sfe, "localmoran",
                features = features, ncol = 2,
                colGeometryName = colGeometryName,
                divergent = TRUE, diverge_center = 0, size = pointsize)
```

#### `Python`

```{python}
#| fig-width: 15
#| fig-height: 10

for feature in features:
    local_moran = Moran_Local(adata[:, feature].X.toarray().astype(np.float64), spatial_weights, transformation="r", permutations=100, seed=3407)
    adata.obs[f"local_moran_{feature}"] = local_moran.Is
    adata.obs[f"local_moran_{feature}_p"] = -np.log10(false_discovery_control(local_moran.p_z_sim*2))
    adata.obs[f"local_moran_{feature}_q"] = local_moran.q.astype(str)
    
fig, axes = plt.subplots(1, len(features), figsize=figsize, layout = "tight")
for feature, ax in zip(features, axes):
    sq.pl.spatial_scatter(
        adata,
        color=f"local_moran_{feature}",
        cmap=cmap_continuous,
        vmin=-adata.obs[f"local_moran_{feature}"].abs().max(),
        vmax=adata.obs[f"local_moran_{feature}"].abs().max(),
        vcenter=0,
        shape=None,
        library_id="spatial",
        title=f"Local Moran's Is: {feature}",
        ax=ax,
        fig=fig,
        size=pointsize,
        scalebar_kwargs={"height_fraction":0.5}
     )
    ax.set_axis_off()
```

:::

### Moran's scatter plot

Local autocorrelation metrics measure the similarity of a given value at a location to the average of its neighbours. Therefore, it is not possible to distinguish "hot spots", where high values are surrounded by high values, from "cold spots", where low values are surrounded by low values, using a local autocorrelation measure because both cases result in high local autocorrelation values.

To overcome this problems one can use the Moran scatter plot [@anselin2019moran] to identify the type of interaction. The Moran scatter plot plots the value at each location versus the average of its neighbours. Taking the average expression as a reference on both axes, one can group each location into one of four different categories: *high-high* (upper right quadrant) representing "hot spots", *low-low* (lower left quadrant) representing "cold spots", *high-low* (lower-right quadrant) and *low-high* (upper-left quadrant).

This information can be combined with significance scores of a local autocorrelation to identify significant hot and cold spots.


::: {.panel-tabset}

#### `R`

```{r}
#| fig-width: 7
#| fig-height: 5

sfe <- runUnivariate(
  sfe,
  features[1],
  colGraphName = colGraphName,
  type = "moran.plot"
)
```

```{r}
moranPlot(sfe,
          features[1],
          graphName = colGraphName,
          swap_rownames = "symbol")
```

#### `Python`

```{python}
#| fig-width: 15
#| fig-height: 10

# Code adapted from ESDA package vignette "Exploratory Analysis of Spatial Data: Spatial Autocorrelation" from https://pysal.org/esda/, license: BSD 3
# (https://nbviewer.org/github/pysal/esda/blob/main/notebooks/Spatial%20Autocorrelation%20for%20Areal%20Unit%20Data.ipynb) 
import libpysal as lps

feature = features[0]

spatial_weights.transform = 'r'
lag_expr = lps.weights.lag_spatial(spatial_weights, adata[:, feature].X.toarray().astype(np.float64))

expr = adata[:, feature].X.toarray().astype(np.float64)
b, a = np.polyfit(expr.flatten(), lag_expr.flatten(), 1)
f, ax = plt.subplots(1, figsize=(9, 9))

plt.plot(expr, lag_expr, '.', color='black')

 # dashed vert at mean of the expr
plt.vlines(expr.mean(), lag_expr.min(), lag_expr.max(), linestyle='--', color = "gray")
 # dashed horizontal at mean of lagged expr 
plt.hlines(lag_expr.mean(), expr.min(), expr.max(), linestyle='--', color = "gray")

# red line of best least squares fit
plt.plot(expr, a + b*expr, 'blue')
plt.title('Moran Scatterplot')
plt.ylabel('Spatial Lag of Expression')
plt.xlabel('Expression')
plt.show()

```
:::


::: {.panel-tabset}

#### `R`

```{r}
#| fig-width: 7.5
#| fig-height: 5

plotLocalResult(
  sfe,
  name = "localmoran",
  features = features[1],
  attribute = "mean",
  colGeometryName = "centroids",
  size = pointsize/2
)
```

We can combine the categories with significance of local Moran's $I$.

```{r}
#| fig-width: 7.5
#| fig-height: 5

localResults(sfe)[["localmoran"]][[1]] <- 
  localResults(sfe)[["localmoran"]][[1]] |> 
  mutate(locClust = ifelse(`-log10p_adj` > -log10(0.05), as.character(mean), "non-siginificant"))

plotLocalResult(
  sfe,
  name = "localmoran",
  features = features[1],
  attribute = "locClust",
  colGeometryName = "centroids",
  size = pointsize/2
)
```

#### `Python`

```{python}
# high-high = 1
# low-high = 2
# low-low = 3
# high-low = 4
fig, ax = plt.subplots(1, 1, figsize=(10, 10))
sq.pl.spatial_scatter(
  adata, 
  color=f"local_moran_{feature}_q",
  shape=None,
  library_id="spatial",
  title=f"Moran scatter plot categories: {feature}",
  ax=ax,
  fig=fig,
  size=pointsize
)
ax.set_axis_off()
plt.show()
```

We can combine the categories with significance levels of local Moran's $I$. 0 indicates non significant regions.

```{python}
q = adata.obs[f"local_moran_{feature}_q"].astype(int)
sig = adata.obs[f"local_moran_{feature}_p"] > -np.log10(0.05)

q_sig = q * sig

adata.obs[f"local_moran_{feature}_q_sig"] = q_sig.astype(str)

fig, ax = plt.subplots(1, 1, figsize=(10, 10))
sq.pl.spatial_scatter(
  adata, 
  color=f"local_moran_{feature}_q_sig",
  shape=None,
  library_id="spatial",
  title=f"Moran scatter plot categories\n with significance: {feature}",
  ax=ax,
  fig=fig,
  size=pointsize
)
ax.set_axis_off()
plt.show()
```

::: 


### Local Geary's $C$ coefficient

Similar to local Moran's $I$, there is a local Geary's $C$ [@anselinLocalIndicatorsSpatial1995] coefficient. It is defined as

$$C_i = \sum_{j=1}^n w_{ij}(x_i-x_j)^2$$

The interpretation is analogous to the global Geary's $C$ (value less than $1$ indicates positive autocorrelation, a value greater than $1$ highlights negative autocorrelation) [@anselinLocalIndicatorsSpatial1995].

::: {.panel-tabset}

#### `R`

```{r}
#| fig-width: 15
#| fig-height: 10

sfe <- runUnivariate(sfe,
                     features = features,
                     colGraphName = colGraphName,
                     type = "localC")

plotLocalResult(sfe, "localC",
                features = features, ncol = 2,
                colGeometryName = colGeometryName,
                divergent = TRUE, diverge_center = 0, size = pointsize)
```

#### `Python`

```{python}
#| fig-width: 15
#| fig-height: 10

for feature in features:
    local_geary = Geary_Local(connectivity=spatial_weights, permutations=100, seed=3407)
    local_geary_result = local_geary.fit(adata[:, feature].X.toarray().astype(np.float64))
    adata.obs[f"local_geary_{feature}"] = local_geary_result.localG
    adata.obs[f"local_geary_{feature}_p"] = -np.log10(false_discovery_control(local_geary_result.p_sim))
    
fig, axes = plt.subplots(1, len(features), figsize=figsize, layout = "tight")
for feature, ax in zip(features, axes):
    sq.pl.spatial_scatter(
        adata,
        color=f"local_geary_{feature}",
        cmap=cmap_continuous,
        vmin=-adata.obs[f"local_geary_{feature}"].abs().max(),
        vmax=adata.obs[f"local_geary_{feature}"].abs().max(),
        vcenter=0,
        shape=None,
        library_id="spatial",
        title=f"Local Geary's Cs: {feature}",
        ax=ax,
        fig=fig,
        size=pointsize
    )
    ax.set_axis_off()
```

::: 

### Local Getis-Ord statistic

The local Getis-Ord $G_i$ [@ordLocalSpatialAutocorrelation1995; @getisAnalysisSpatialAssociation1992] statistic quantifies the weighted concentration of points within a radius $d$ and in a local region $i$, according to:

$$G_i(d) = \frac{\sum_{j \neq i } w_{ij}(d)x_j}{\sum_{j \neq i} x_j}$$

There is a variant of this statistic, $G_i^*(d)$, which is the same as $G_i(d)$ except that the contribution when $j=i$ is included in the term [@getis1996local].

The interpretation of the local Getis-Ord statistic $G_i(d)$ is the same as for the global variant. The easiest is to calculate a $z$-statistic. If this value is positive, we call the region a hotspot, if it is negative, we call it a cold spot [@anselin2024introduction].

::: {.panel-tabset}

#### `R`

```{r}
#| fig-width: 15
#| fig-height: 10

sfe <- runUnivariate(sfe,
                     features = features,
                     include_self = FALSE, # this would specify G_i^*(d),
                     colGraphName = "binary",
                     type = "localG")

plotLocalResult(sfe, "localG",
                features = features,
                ncol = 2,
                colGeometryName = colGeometryName,
                divergent = TRUE, diverge_center = 0, size = pointsize)
```

#### `Python`

```{python}
#| fig-width: 15
#| fig-height: 10

for feature in features:
    local_getis_ord = G_Local(adata[:, feature].X.toarray().astype(np.float64), spatial_weights, transform="B", star=False, permutations=1000, seed=3407)
    adata.obs[f"local_getis_ord_{feature}"] = local_getis_ord.Zs
    adata.obs[f"local_getis_ord_{feature}_p"] = -np.log10(false_discovery_control(local_getis_ord.p_norm))
    
fig, axes = plt.subplots(1, len(features), figsize=figsize, layout = "tight")
for feature, ax in zip(features, axes):
    sq.pl.spatial_scatter(
        adata,
        color=f"local_getis_ord_{feature}",
        cmap=cmap_continuous,
        vmin=-adata.obs[f"local_getis_ord_{feature}"].abs().max(),
        vmax=adata.obs[f"local_getis_ord_{feature}"].abs().max(),
        vcenter=0,
        shape=None,
        library_id="spatial",
        title=f"Local Getis-Ord $G_i$: {feature}",
        ax=ax,
        fig=fig,
        size=pointsize
    )
    ax.set_axis_off()
```

:::

The results above give an estimate of the local Getis-Ord statistic for each cell, but no significance value. This can be done by using a permutation approach using the `localG_perm` argument.

Positive values indicate clustering of high values, i.e., hot spots, and negative values indicate clustering of low values, i.e., cold spots. The method does not detect outlier values because, unlike in local Moran's $I$, there is no cross-product between $i$ and $j$. But unlike local Moran's $I$, we know the type of interaction (high-high or low-low) between $i$ and $j$ [@anselin2009geoda; @anselin2024introduction].

### Local spatial heterosceadiscity (LOSH)

The local spatial heteroscedasticity (LOSH) [@ordLocalSpatialHeteroscedasticity2012] is a measure of spatial autocorrelation that is based on the variance of the local neighbourhood. Unlike the other measures, this method does not assume homoscedastic variance over the whole tissue region. LOSH is defined as:

$$H_i(d) = \frac{\sum_j w_{ij}(d)|e_j(d)|^a}{\sum_j w_{ij}(d)}$$

where $e_j(d) = x_j - \bar{x}_i(d), j \in N(i,d)$ are the local residuals that are subtracted from the local mean. The power $a$ modulates the interpretation of the residuals ($a=1$: residuals are interpreted as absolute deviations from the local mean; $a=2$: residuals are interpreted as deviations from the local variance) [@ordLocalSpatialHeteroscedasticity2012].

The LOSH should be interpreted in combination with the local Getis-Ord $G_i^*$ statistic. The $G_i^*$ quantifies the local mean of the variable of interest, while $H_i$ quantifies the local variance. This table provided by Ord and Getis [@ordLocalSpatialHeteroscedasticity2012] summarizes the interpretation of the combination of $G_i^*$ and $H_i$.

|                         | high $H_i$                                                                    | low $H_i$                                                                                                                      |
|---------------|---------------------|------------------------------------|
| large $\|G_i^*\|$       | A hot spot with heterogeneous local conditions                                | A hot spot with similar surrounding areas; the map would indicate whether the affected region is larger than the single “cell” |
| small $\|G_i^*\|$ | Heterogeneous local conditions but at a low average level (an unlikely event) | Homogeneous local conditions and a low average level                                                                           |

::: {.panel-tabset}

#### `R`

```{r}
#| fig-width: 15
#| fig-height: 10

# run localG with permutation test
sfe <- runUnivariate(sfe,
                     features = features,
                     colGraphName = colGraphName,
                     type = "LOSH")


plotLocalResult(sfe, "LOSH",
                features = features,
                colGeometryName = colGeometryName,
                size = pointsize)
```

#### `Python`

```{python}
#| fig-width: 15
#| fig-height: 10

for feature in features:
    losh = LOSH(connectivity=spatial_weights,  inference="chi-square")
    losh_result = losh.fit(adata[:, feature].X.toarray().astype(np.float64))
    adata.obs[f"losh_{feature}"] = losh_result.Hi
    
fig, axes = plt.subplots(1, len(features), figsize=figsize, layout = "tight")
for feature, ax in zip(features, axes):
    sq.pl.spatial_scatter(
        adata,
        color=f"losh_{feature}",
        cmap="Blues",
        vmin=0,
        vmax=adata.obs[f"losh_{feature}"].abs().max(),
        shape=None,
        library_id="spatial",
        title=f"Local spatial heteroscedasticity: {feature}",
        ax=ax,
        fig=fig,
        size=pointsize
    )
    ax.set_axis_off()
```

:::

## A note of caution

The local methods presented above should always be interpreted with care, since we face the problem of multiple testing when calculating them for each cell. Moreover, the presented methods should mainly serve as exploratory measures to identify interesting regions in the data. Multiple processes can lead to the same pattern, thus from identifying the pattern we cannot infer the underlying process. Indication of clustering does not explain why this occurs. On the one hand, clustering can be the result of spatial interaction between the variables of interest. We have an accumulation of a gene of interest in one region of the tissue. On the other hand clustering can be the result spatial heterogeneity, when local similarity is created by structural heterogeneity in the tissue, e.g., that cells with uniform expression of a gene of interest are grouped together which then creates the apparent clustering of the gene expression measurement [@zuurAnalysingEcologicalData2007; @pebesmaSpatialDataScience2023; @anselin2024introduction].
