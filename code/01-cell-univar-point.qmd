# Discrete Marks

{{< include theory/01-theory-point.qmd >}}

## Univariate viewpoint

In the following document we will often compare the distribution of mature oligodendrocytes (OD mature cells) across different z-slices of the same tissue. We assume these slices to be enough far away to be considered independent. Therefore, we assume that these patterns were generated independently by different point processes. Since we consider the dependence of one mark among itself, we are in a univariate setting per slide. We compare several univariate curves along different z-slices, which is in turn a multivariate comparison [@baddeleySpatialPointPatterns2015, pp. 565].

In our example dataset we analyse the mouse preoptic hypothalamus [@moffittMolecularSpatialFunctional2018]. This is a tissue of the mouse brain that is cut out of a bigger context. The lower boundary is the end of the tissue whereas the upper three boundaries are a technical boundary. Therefore, our example is a mixture between window sampling and the small world model. In order to decrease the bias of the tissue boarder, we use the Ripley-Rasson estimate of a spatial domain to estimate the sampling window.

```{r, fig.width=12, fig.height=6, cache=FALSE, message= FALSE}
par(mfrow=c(1,3))
#Plot the marks separately 
lapply(zstack_list, function(zstack){
  plot(pp_ls[[zstack]][[celltype_ls]], main = zstack, legend = FALSE)
})
dev.off()

pls <- lapply(zstack_list, function(zstack){
  pp_sel <- pp_ls[[zstack]][[celltype_ls]]
  p <- pp_sel |> as.data.frame() |> 
  ggplot(aes(x = x, y = y, alpha = 0.3)) +
  geom_point() +
  theme_minimal() +
  coord_fixed() +
  ggtitle(zstack)
  return(p)
})
wrap_plots(pls, guides = 'collect')
```

## Correlation

Correlation, or more generally covariance, represents a second-order summary statistic and measures dependence between data points [@baddeleySpatialPointPatterns2015, pp. 199].

### Ripley's $K$

#### Empirical Ripley's $K$

In the framework of correlation analysis, we often look at distances $d_{ij} = ||x_i-x_j||$ of all points. It is then natural to look at the summary of these distances, $d_{ij}$, e.g. as a histogram. The histogram of this point process depends on the observation window $W$, thus the histogram can change significantly with a different window. Therefore, we look at the empirical distribution function of the distances $d_{ij}$ that are smaller or equal than a radius $r$  [@baddeleySpatialPointPatterns2015, pp. 203]

What we actually measure here is "the average number of r-neighbours of a typical random point"  [@baddeleySpatialPointPatterns2015, pp. 204]. This number is still dependent on the size of the observation window so we can standardise it by the number of points and the window size, $|W|$. We then obtain the empirical Ripley's $K$ function  [@baddeleySpatialPointPatterns2015, pp. 204]:

$$
\hat{K}(r) = \frac{|W|}{n(n-1)}\sum_{i=1}^n\sum_{j=1 \\j \neq i}^n\{d_{ij}\leq r\} e_{ij}(r)
$$

The standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. However, using the empirical $K$ function assumes though that the point process has homogeneous intensity, which is often not the case for biological tissue  [@baddeleySpatialPointPatterns2015, pp. 204-205]. We will return to this issue below in the ``Correcting for Inhomogeneity``. The term $e_{ij}(r)$ is for edge correction. We will briefly cover this in ``Edge effects and their corrections for spatial metrics``

#### Edge effects and their corrections for spatial metrics

Edge effects describe the phenomenon that not the entire point process is observed, but rather only the part within the window $W$. This means the value of various statistics could be biased along the edges [@baddeleySpatialPointPatterns2015, pp. 213].

There are many corrections for edge effects that are briefly listed here [@baddeleySpatialPointPatterns2015, pp. 214-219]:

Border correction:

In border correction the summation of data points is restricted to $x_i$ for which $b(x_i,r)$ is completely in the window $W$.

Isotropic correction:

We can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.

Translation correction:

A stationary point process $X$ is invariant to translations. So the entire point process can be shifted by a vector $s$ to be at the position $X+s$.

### The $L$-function

The $K$-function can be ``centered'', which is then called the $L$-function. The $L$-function is a variance-stabilising version of the $K$-function [@caneteSpicyRSpatialAnalysis2022]:

$$
L(r) = \sqrt{\frac{K(r)}{\pi}}.
$$

### Pair Correlation function

We have seen above that the $K$-function is cumulative. That is, the contributions of all distances smaller equal to $r$ are considered. An alternative is to take the derivative of the $K$-function in order to obtain contributions of distances between points equal to $r$, according to:

$$
g(r) = \frac{K'(r)}{2\pi r},
$$

where $g(r)$ is the derivative of the $K$ function (so interactions at exactly $r$) divided by the probability of a poisson process at this radius [@baddeleySpatialPointPatterns2015, pp. 225].

```{r, error=FALSE, message=FALSE, warning=FALSE, results='hide', include=TRUE}
#| message: false
#| warning: false

#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate
#POST: result of the metric
metricRes <- function(plot_by, pp, celltype, fun, bootstrap, continuous, f){
  if(continuous){
    pp <- subset(pp, select = plot_by)
  }
  else{
    pp_sel <- pp[[plot_by]]
    pp <- subset(pp_sel, marks == celltype)
  }
  if(bootstrap){
    metric.res <- lohboot(pp, fun = fun, f = f)
  }
  else{
    metric.res <- do.call(fun, args = list(X=pp, f=f))
  }
  metric.res$type <- celltype
  metric.res$plot_by <- plot_by
  return(metric.res)
}

#PRE: celltypes, function to calculation and edge correction method
#POST: dataframe of 
metricResToDF <- function(plot_by, celltype, pp, fun, edgecorr, bootstrap, continuous, f){
  lapply(plot_by, function(u) {
    metricRes(u, fun = fun, pp = pp, celltype = celltype, bootstrap, continuous, f)  %>%
      as.data.frame()
  }) %>% bind_rows
}

# [MR: try to write the above a little more compactly]

#PRE: Celltypes of interest, function to analyse, edge correction to perform
#POST: plot of the metric
plotMetric <- function(plot_by, pp, celltype = NULL, x, fun, edgecorr, bootstrap = FALSE, continuous = FALSE, f = NULL){
  #calculate the metric and store as dataframe
  res_df <- metricResToDF(plot_by, celltype, pp, fun, edgecorr, bootstrap, continuous, f)
  #plot the curves
  p <- ggplot(res_df, aes(x=.data[[x]], y=.data[[edgecorr]], colour= (plot_by),  show.legend = FALSE))+
      geom_line() +
      {if(bootstrap)geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25, show.legend = FALSE)}+
      ggtitle(paste0(fun, '-function'))+
      geom_line(aes(x=.data[[x]],y=theo),linetype = "dashed")+
      ylab(edgecorr) +
      #guides(colour = guide_legend(override.aes = list(shape = 23, size = 2))) +
      theme_light()
  
  return(p)
}

p_K <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Kest', 'iso', bootstrap = TRUE)
p_L <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Lest', 'iso', bootstrap = TRUE)
p_g <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'pcf', 'border', bootstrap = TRUE)
```

```{r, cache=FALSE, fig.height = 6, fig.width = 16, include=TRUE}
p_homo <- wrap_plots(list(p_K,p_L,p_g), guides = 'collect')
p_homo
```

As we have seen above in the test for homogeneity in oligodendrocytes, the assumptions of homogeneity are not given in our data. Therefore, we will have to use the inhomogeneous alternatives (inhomogeneity correction and local scaling) of the metrics instead.

### Correcting for Inhomogeneity

#### Inhomogeneous $K$-function

In the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account in the analysis. Biological point patterns display inhomogeneity very often, therefore this analysis is preferred over the homogeneous alternatives. Inhomogeneous alternatives can be estimated via:
<!--
$$
K_{inhom}(r) = \mathbb{E} \left[\sum_{x_j \in X} \frac{1}{\lambda(x_j)}\mathbb{1}\{0<||u-x_j||\leq r\}|u \in X\right].
$$

This theoretical quantity can be approximated with estimators such as:

$$
\hat{K}_{inhom}(r) = \frac{1}{D^p|W|}\sum_i\sum_{j \neq i} \frac{\mathbb{1}\{||u-x_j||\leq r\}}{\hat{\lambda}(x_j)\hat{\lambda}(x_i)}e(x_j,x_i;r),
$$

where $e(u,v;r)$ is an edge correction weight, $\hat{\lambda}(u)$ is an estimator of the intensity of $u$ and $D$ is the following [1]: 

$$
D = \frac{1}{|W|}\sum_i \frac{1}{\hat{\lambda}(x_i)}
$$

[MR: just wondering how important all these formulas are? Do we want a full mathematical description, or does the mathematical description still help us to unpack what is needed for the common situation of inhomogeneous point patterns?]
-->


$$
\hat{K}_{inhom}(r) = \frac{1}{D^p|W|}\sum_i\sum_{j \neq i} \frac{\mathbb{1}\{||u-x_j||\leq r\}}{\hat{\lambda}(x_j)\hat{\lambda}(x_i)}e(x_j,x_i;r),
$$

where $e(u,v;r)$ is an edge correction weight and $\hat{\lambda}(x_i)$ is an estimator of the intensity at point $x_i$. The inhomogeneity correction happens via these $\hat{\lambda}(x_i)$ per point $x_i$. The estimation of these local intensities can happen in a data-dependent manner via kernel-smoothing. As this is the same data to then calculate the metric on, this can lead to biases. However, in the case where the local intensities are known, the inhomogeneous $K$ function is an unbiased estimator [@baddeleySpatialPointPatterns2015, pp. 243-244].


```{r, error=FALSE, message=FALSE, warning=FALSE, results='hide'}
p_K <- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r','Kinhom', 'iso', bootstrap = TRUE)
p_L <- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r', 'Linhom', 'iso', bootstrap = TRUE)
p_g <- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r', 'pcfinhom', 'border', bootstrap = TRUE)
```

```{r, cache=FALSE, fig.height = 6, fig.width = 16}
p_inhomo <- wrap_plots(list(p_K,p_L,p_g), guides = 'collect')
p_inhomo
```

The inhomogeneous $K$-function tells us that the microglia cells follow close to a Poisson process (dashed line) closely and can therefore be assumed to be randomly distributed and not clustered. Ependymal cells show a high degree of clustering at a low radius $r$. OD mature cells exhibit a medium level of clustering.

In the $L$-function, the microglia cells are along the dashed Poisson line, indicating no clustering; ependymal cells are highly clustered at low values of $r$, whereas OD mature show intermediate clustering.

The pair correlation function is the derivative of the $K$-function. The pcf plot gives similar information as before: microglia cells are around the dashed Poisson line. OD Mature cells show a rather broad range of correlations between $r \in [20,100]$. Ependymal cells have a very strong correlation at $\sim r = 25$.

Interestingly, the curves for the inhomogeneous functions of ependymal cells and OD mature cells cross the poisson line at $r=300$. This means that the inhomogeneous functions find repulsion of ependymal cells and OD mature cells past a radius of $r=300$.   

<!--
We should further note that the inhomogeneity correction assumes that the process is correlation stationary, meaning that the summary statistics are the same in each quadrat. This is clearly violated at least for Ependymal cells and OD mature cells [MR: how do we know this is violated? Can we test somehow also for this departure?]. Therefore, the question remains whether acounting for one issue (homogeneity) via a correction that assumes correlation stationarity does not just exchange one problem for another. Nonetheless, these measures do give some quantitative summaries of clustering .. [MR: should we add a sentence like this? Otherwise, it does question whether it is valid to do any of this.]
-->

### Local Scaling

#### Locally-scaled $K$-function

In the inhomogeneous $K$-function approach above, we assume that the intensities can vary locally but the scale of the point process is not changed. This means that while the intensities might vary in the parts of the point pattern, the pattern in one subquadrat is not just a scaled version of another subquadrat. In a biological sample, this assumption is easily violated,  e.g. when a gradient of cells increases from one side to another [ME needs a reference]. The correlation structure might scale linearly with the distance [@baddeleySpatialPointPatterns2015 pp. 246-247] [@prokesovaStatisticsLocallyScaled2006].

To circumvent this local scaling, we can assume that the process is subdivided into small regions. In these small regions, the point process is a scaled version of a template process. This template process needs to be both stationary and isotropic [@baddeleySpatialPointPatterns2015 pp. 246-247].

#### Locally-scaled $L$-function

Since the $L$-function is simply a transformation of the $K$-function, the same local scaling framework can be applied to the $L$-function [@baddeleySpatialPointPatterns2015 pp. 246-247].

```{r, error=FALSE, message=FALSE, warning=FALSE, results='hide', include=TRUE}
p_K <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Kscaled', 'iso', bootstrap = FALSE)
p_L <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Lscaled', 'iso', bootstrap = FALSE)
#p_g <- plotScaledMetric(zstack_list,celltype_ls, pp_ls, 'pcfscaled', 'iso')$p
```


```{r, cache=FALSE, fig.height = 6, fig.width = 16, include=TRUE}
p_scaled <- wrap_plots(list(p_K, p_L), guides = 'collect')
p_scaled
```

As seen by our permutation tests we have grounds to believe that the patterns of ependymal and OD mature cells are locally scaled. Therefore, we will analyse this pattern using a locally scaled K and L function. 

We see, that again our ependymal cells are very far from the poisson process line, indicating strong clustering among ependymal cells. The OD mature cells range in the middle showing intermediate clustering

```{r, cache=FALSE, fig.height = 10, fig.width = 16, include=TRUE}
wrap_plots(list(p_homo, p_inhomo, p_scaled), nrow = 3, guides = 'collect')
```

In the section on homogeneity vs. inhomogeneity above we have argued using permutation tests that our pattern is not homogeneous but rather inhomogeneous. In fact, both OD mature cells and ependymal cells even show local scaling in the permutation test. In the plot above we see all variants of the correlation metrics. Given the assumptions of either homogeneity (first row), inhomogeneity (second row) and local scaling (third row) changes the interpretation to some extent. 

Deciding whether a pattern is homogeneous or not is easy and should always be done. In fact, most biological tissue will be inhomogeneous. The kind of inhomogeneity is more difficult to determine. Since the inhomogeneous curves (second row) and the local scaling curves (third row) are very different, it matters a lot to have good grounds to assume one or the other. Given our permutation tests above, we see that most support is found for local scaling metrics. 

All the variants assume something about the properties of the metrics and given valuable insights. In the choice which metric fits the most, some care has to be taken.

#### Local Indicators of Spatial Association

It is worth noting that the $K$- and $L$-functions described above are summary statistics over the entire pattern (i.e., averaged over all points). However, if we know that there are different regions in our point pattern, an alternative strategy is to compute ``local'' contributions to these patterns, i.e., local $K$- ,$L$- or pair-correlation functions. Baddeley et. al. propose to compare these $n$ functions with so-called functional principal component analysis (see below). We will show here the example of the LISA version of the $L$-function [@baddeleySpatialPointPatterns2015 pp. 247-248].

##### Local $L$ function

```{r, error=FALSE, message=FALSE, warning=FALSE, results='hide'}
L_odmature_lisa <- localL(pp_ls[['0.01']]$`OD Mature`)

df <- as.data.frame(L_odmature_lisa)
dfm <- reshape2::melt(df, "r")

get_sel <- dfm %>% filter(r > 200.5630 & r < 201.4388, variable != "theo") %>%
  mutate(sel = value) %>% select(variable, sel)

dfm <- dfm %>% left_join(get_sel)

p <- ggplot(dfm, aes(x=r, y=value, group=variable, colour=sel)) +
  geom_line() + 
  scale_color_continuous(type = "viridis") +
  geom_vline(xintercept = 200) +
  theme(legend.position = "none") +
  theme_light() +
  ggtitle("LISA curves of slice 0.01")

ppdf <- as.data.frame(pp[['0.01']]) %>% filter(marks=="OD Mature")
ppdf$sel <- get_sel$sel # assume they are in same order

q <- ggplot(ppdf, aes(x=x, y=y, colour=sel)) + 
  geom_point() +
  scale_color_continuous(type = "viridis") +
  theme(legend.position = "none") +
  theme_light()+
  ggtitle("Points coloured by LISA value at r ~ 200")
```


```{r, fig.height=5, fig.width=10}
p|q
```

In the case of the OD mature cells, we obtain further information with this plot. We note that there are two distinct populations of curves: those that are clearly above the mean LISA curve in black and others that are around/underneath. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger clustering and less clustered regions.

There are inhomogeneous versions of these (e.g. `localLinhom`) that are not shown here for brevity.

##### Functional PCA for the $n$ Curves

We apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA but applied to functional data (i.e., each observation is a function instead of a point). For the $n$ functions above, functional PCA will recover the main trends in the data [@ramsayPrincipalComponentsAnalysis2005]. We use the R package fdapace to perform functional PCA [@zhouFdapaceFunctionalData2022]. 

```{r, error=FALSE, message=FALSE, warning=FALSE, results='hide'}
#adapted from the fdapace vignette
functional.pca.pp <- function(df){
  df_fdob <- asinh(df %>% as.matrix / 50)  # [MR: should we transform? if so, how?]
  #df_fdob <- df %>% as.matrix # [MR: should we transform? if so, how?]
  #remove theo column - we want only the actual estimations in there without the Poisson line theo
  if('r' %in% colnames(df) || 'theo' %in% colnames(df))
     df_fdob <- df_fdob[,!colnames(df_fdob) %in% c("r", "theo")]
  if('Ependymal' %in% colnames(df))
    df_fdob <- df_fdob[,!colnames(df_fdob) %in% c("trans",'iso')]

  #number of columns
  N <- ncol(df_fdob)
  #number of rows
  M <- nrow(df_fdob)
  #the x values at which all the curves were evaluated, here called tVec
  s <- df$r
  #create the FPCA object
  fd_obj <- fdapace::MakeFPCAInputs(IDs = rep(1:N, each=M),
                                    tVec=rep(s,N), yVec=df_fdob)
  print(which( unlist( lapply(fd_obj$Lt, 
                              function(x) length(x) != length(unique(x))))))
  #check that the FPCA object is valid
  fdapace::CheckData(fd_obj$Ly, fd_obj$Lt)
  #run the computation of the FPCA - would work with sparse data.
  fpca_obj <- fdapace::FPCA(fd_obj$Ly, fd_obj$Lt, 
                            list(plot = TRUE, dataType='Dense', kernel='rect'))
  fdapace::CreatePathPlot(fpca_obj,K = 3, pch = 4,
                          showObs = FALSE, showMean = TRUE)
  return(fpca_obj)
}

fpca_obj <- functional.pca.pp(L_odmature_lisa)
fpca_pc_df <- as.data.frame(fpca_obj$xiEst) %>% 
  rename(PC1 = V1, PC2 = V2, PC3 = V3)
fpca_pc_df$sel <- get_sel$sel # assume they are in same order

p_biplot <- ggplot(fpca_pc_df, aes(x=PC1, y=PC2, col = sel)) + 
  scale_color_continuous(type = "viridis") +
  geom_point() +
  theme_light() +
  ggtitle("Biplot of the LISA L curves")
p_biplot

p1 <- ggplot(ppdf, aes(x=x, y=y, colour = fpca_pc_df$PC1)) + 
  scale_color_continuous(type = "viridis") +
  theme_light() +
  geom_point()

p2 <- ggplot(ppdf, aes(x=x, y=y, colour = fpca_pc_df$PC2)) + 
  scale_color_continuous(type = "viridis") +
  theme_light() +
  geom_point()

p1|p2
```

```{r, include=FALSE}
#assemble plots for paper
p_L <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Lest', 'iso', bootstrap = TRUE)
p_local <- wrap_plots(list(p,p_biplot), nrow = 2, guides = 'collect')
L_plot <- wrap_plots(list(p_L, p_local), nrow = 2, heights = c(1, 2))
```

```{r, fig.height=5, fig.width=10}
```

Here, we see the functional PCA for the OD mature cells. The Design plot tells us that we have a very dense dataset over the entire support [MR: do we need the 'Design plot'? it doesn't show much]. The mean curve displays the mean trend over all $n$ LISA $L$-curves (which is itself similar to the locally-scaled $L$-function). The scree plot indicates that the first eigenfunction explains more than $80 \%$ of the variance. The eigenfunction curves in the bottom right panel indicate the deviation from the mean curve.

Looking at the second plot, we see the smoothed mean curve and the individual curves that are reconstructed from the first three eigenfunctions. The first eigenfunction from the bottom right panel, $\phi_1$, is above the mean curve, which relates to the population of curves above the mean. $\phi_2$ is first above the mean curve and then lower than the mean curve. These curves are visible as well. Lastly, $\phi_3$ is curves that start low and pick up to be larger than the mean curve in the end. This is visible in e.g. the orange dashed line [@ramsayPrincipalComponentsAnalysis2005].

The last plot shows the biplot of the loadings of the functional PCA. Each point is a cell from the OD mature cells with the loadings of the first two principal components plotted. The points are coloured as they were in the plots of the LISA $L$-curves. The first principal component clearly separates the two populations. 

### Third-Order Summary Statistics

So far we have considered first- and second-order summary statistics and local (or inhomogeneous) adaptations of them. In the second order, one considers (counts of) pairs (e.g., $K$ function). In a third-order setting, we would count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius r [@baddeleySpatialPointPatterns2015 pp. 249].

<!--
$$
T(r) = \frac{1}{\lambda^3}\mathbb{E}\left[\sum_{i=1}^n\sum_{j=1\\j\neq i}^nm(x_i,x_j,u) | u \in X\right]
$$

here m is the maximum side of the triangle

$$
m(a,b,c) = \max(||a-b||,||a-c||,||b-c||)
$$

```{r, include=FALSE, eval=FALSE}
p <- plotMetric(zstack_list, pp_ls, celltype_ls, 'r', 'Tstat', 'border', bootstrap = FALSE)
p
```

[MR: should we skip the plot in this section?]
-->
## Spacing

So far, most approaches considered intensity and correlation as measures to assess a point pattern. Next, we will look at measures of spacing and shortest-distances to assess spatial arrangements [@baddeleySpatialPointPatterns2015 pp. 255].

Baddeley et.al. summarises three basic distances to measure:

-   pairwise distance: $d_{i,j} = ||x_i-x_j||$
-   NN distances: $d_i = \min_{j \neq i}d_{ij}$
-   empty-space distance: $d(u) = \min_j||u-x_j||$

Note also that there are tests of CSR that are based on spacing, including the Clark-Evans and Hopkins-Skellam Index tests that were discussed above ``Testing for CSR''.

### Nearest Neighbour approaches

Nearest neighbour (NN) methods are based on the notion of "nearness". In particular, we introduce `nndist` from `spatstat`, a method to calculate the distances until $k$ NN are found. This function returns a density for each specified $k$ for the $k$ neighbour distances. We can for instance collapse the $k$ curves into a mean curve per point pattern. This information of the mean nearest neighbour distance (MMND) can be summarised as a density. Note, that these distances are "raw" nearest-neighbour distances which are not corrected for edge effects. Edge correction for the nearest neighbour distance ($k = 1$) is implemented in the function `Gest` below [@baddeleySpatialPointPatterns2015 pp. 256] [@baddeleySpatstatPackageAnalyzing2005].

```{r, cache=FALSE}
nndistance <- function(pp, nk){
  xy <- cbind(pp$x, pp$y)
  nndistances_k15 <- nndist(xy, k = nk) 
  nndistances_mean <- rowMeans(nndistances_k15)
  return(nndistances_mean)
}

#PRE: list of point pattern, corresponding celltypes of interest, functions to evaluate
#POST: result of the metric
metricRes_nndist <- function(ppls, celltype, fun){
  metric.res <- list(res = do.call(fun, args = list(pp=ppls[[celltype]], nk = seq(1:15))))
  metric.res$type = celltype
  return(metric.res)
}
# [MR: again, this function looks again like those before and maybe could be done as an all-in-one wrapper.]
celltypes <- c("Ependymal", "OD Mature", "Microglia")
#go through all defined celltypes and calculate the nearest-neighbour distance
res_ls <- lapply(celltypes, metricRes_nndist, fun = nndistance, ppls = pp_ls[['0.01']])
#initialise a dataframe for the metric values and the type information
res_df <- data.frame(metric = numeric(0), type = character(0))
# Loop through the res_ls list and combine the metric values with their corresponding type - ChatGPT
for (i in 1:length(res_ls)) {
  metric_values <- res_ls[[i]]$res
  metric_type <- rep(res_ls[[i]]$type, length(metric_values))
  df <- data.frame(metric = metric_values, type = metric_type)
  res_df <- rbind(res_df, df)
}
#plot the densities
p <- ggplot(res_df, aes(x=metric, col= type))+
    geom_density(linewidth=1)+
    scale_x_sqrt() +
    theme_light() +
    ggtitle('Sqrt of the Mean Nearest-Neighbour Distance')
p
```

In the MNND empirical distribution, the ependymal cells show the shortest NN distances, a reflection of their clustering. The OD mature cells have larger NN distances as well as a bimodal distribution, indicating a mix of longer and wider distances (as visible in the LISA $L$-functions). Microglia cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.

### Nearest-neighbour function $G$ and empty-space function $F$

#### Definitions of $F$ and $G$ function

Under a stationary spatial point process, the empty-space distance is defined as:

$$
d(u,X) = \min\{||u-x_i||: x_i \in X\}
$$

Note that this is an edge-corrected distribution function of the nearest-neighbour distance above.

[MR: what does one do for a non-stationary process?] [ME: that is a very good question, basically all point pattern methods assume stationarity]

The empty space function is then the cumulative distribution function of the empty-space distances defined above:

$$
F(r) = \mathbb{P}\{d(u,X)\leq r\}.
$$

The NN distance is defined as:

$$
d_i = \min_{j\neq i}||x_j-x_i||.
$$

The NN distance distribution function $G(r)$ is then defined as:

$$
G(r) = \mathbb{P}\{d(x,X\backslash u \leq r |X\ has\ a\ point\ at\ u\}.
$$

For a homogeneous Poisson process, the NN distance distribution is identical to the empty-space function of the same process:

$$
G_{pois} \equiv F_{pois}.
$$

For a general point process, the $F$ and $G$ functions are different [@baddeleySpatialPointPatterns2015 pp. 261-264].

### Empty-space hazard

The $F$ and $G$ functions are, like the $K$ function, cumulative. The same disadvantages as with the $K$ function occur here too [MR: what disadvantages? maybe say them explicitly here]. Therefore, an analogue to the pair-correlation function would make sense to consider. For practical reasons, this is no longer the derivative of the $F$ function but rather a hazard rate:

$$
h(r) = \frac{f(r)}{1-F(r)}.
$$

For a CSR process, the hazard rate is:

$$
h_{pois}(r) = 2 \pi \lambda r
$$

(i.e., linear in $r$)  [@baddeleySpatialPointPatterns2015 pp. 271-274].
 
### $J$-Function

The concepts of the empty-space function $F$ and the NN function $G$ are somewhat complementary. If one decreases, the other increases.

Thus, a related approach is the $J$ function:

$$
J(r) = \frac{1-G(r)}{1-F(r)}.
$$

For a CSR process, $J_{pois} \equiv 1$, whereas values of $J(r) > 1$ are consistent with a regular (e.g., repelling) pattern, and \$J(r) \< 1 represents a clustered process  [@baddeleySpatialPointPatterns2015 pp. 274-276].

```{r, fig.height = 10, fig.width = 7}
p_G <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Gest', 'rs', bootstrap = FALSE)
p_F <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Fest', 'rs', bootstrap = FALSE)
p_J <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Jest', 'rs', bootstrap = FALSE)
```

```{r, cache=FALSE, fig.height = 6, fig.width = 16}
wrap_plots(list(p_G,p_F,p_J), guides = 'collect')
```

### Accounting for Inhomogeneity in Spacing Functions

[MR: so if there are inhomogeneous versions, should we skip the plots above? Or not, because the inhomogeneous versions are inaccurate because they still assume correlation stationarity. What do we do?!? We need to be careful not to paint overselves into a corner.]

There are inhomogeneous variants of the spacing functions explained above

```{r}
p_G <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Ginhom', 'bord')
p_F <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Finhom', 'bord')
p_J <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'r', 'Jinhom', 'bord')
```

```{r, cache=FALSE, fig.height = 6, fig.width = 16}
wrap_plots(list(p_G,p_F,p_J), guides = 'collect')
```

[ME: add some text to inhomogeneity]

### Nearest-Neighbour Orientation

Next to the NN distance, we can estimate the *orientation* of the neighbours, which gives an indication of the orientation of the spacing. It works by taking the angle between each point and its $k^{th}$ nearest neighbour. The angle is anticlockwise from the x-axis [@baddeleySpatialPointPatterns2015 pp. 278-279] [@baddeleySpatstatPackageAnalyzing2005].


```{r}
p <- plotMetric(plot_by = zstack_list, pp, celltype_ls, 'phi', 'nnorient', 'bordm', bootstrap = FALSE)
p
```

The values of $\phi$ correspond to the orientation of the point pattern. The horizontal axis goes from $180$ to $0$ (left to right) and the vertical from $90$ to $270$ (top to bottom) [MR: I find this description quite confusing, because you are not talking about the horizontal/vertical axis of the metric plot, but rather the orientations in the point patterns. And since certain $\phi$s represent these orientations, is it worth adding some shading of the x-axis to highlight this? Thicker lines would also benefit the old people reading this. And I wonder if faceting on celltype would help also. What does the Y-axis represent? And are there local variants of these? Maybe the clustered OD cells have a different orientation than the non-clustered?].

We can infer that the orientation of the Ependymal NNs is primarily along the vertical axis, OD mature cells do not show a clear orientation and microglial cells a horizontal orientation in their NNs with a modest peak at $\sim 180$ (orientation to the top).

Note also tha the concepts of spacing are not only usable in *point* pattern analysis but also more broadly in other spatial contexts (e.g., spacing between shapes instead of points).

### Edge Corrections

The same consideration about edge effects as for the $K$ (and related) functions need to be made for the spacing functions; uncorrected estimates are negatively biased estimators. The easiest approach is to draw an artificial border and consider NNs within it. Other approaches are based on sampling. Yet another approach relates to survival analysis, with the idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and "dies". This gives survival distributions similar to censored data, where the Kaplan-Meier estimator is the optimal choice  [@baddeleySpatialPointPatterns2015 pp. 286-292].

# Continuous Marks

## Setup

```{r, message=FALSE}
#| label: load-data 2
# redefine the pp here to be zstack 0.01
pp <- pp[['0.01']]
#subset the data to only look at sample ID 0.01
sub_2CT = spe[, spe$sample_id == "0.01" & spe$cluster_id %in% c("Astrocyte", "Inhibitory")]
(pp_2CT = .ppp(sub_2CT, marks = "cluster_id"))

sub <- spe[, spe$sample_id == '0.01']
#[MR: this above never gets used?]
```


In `spatstat`, a `mark` can basically take any value, discrete (as we have seen above) or  continuous (e.g., gene expression). In our example, we take the gene expression of some marker genes from Fig. 6 of the original publication [@baddeleySpatialPointPatterns2015 pp. 637] [@moffittMolecularSpatialFunctional2018]. This is a typical numerical mark for points in a biological dataset.

```{r}
#  Genes from Fig. 6 of Moffitt et al. (2018)
genes <- c('Slc18a2', 'Esr1', 'Pgr')
gex <- assay(sub)[genes,] %>% t %>% as.matrix %>% 
  data.frame %>% set_rownames(NULL)
# gene expression to marks [ME: is it really expression?]
marks(pp) <- gex
```

> TODO: better plotting?

```{r}
plot(pp)
```

Here we see spatial distribution of the counts of the three genes Slc18a2, Esr1 and Pgr. The size of the circles indicates the counts of the transcripts at that spot. [ME: is this true?] Since there are really a lot of points, we can't easily distinguish general patterns of count distributions.

We can investigate the distribution of the marks against the spatial location of the points and against each other. This is done with the function `pairs` from `spatstat`. It generates a scatterplot of the counts of the marks (in our case the three genes) against each other and against the $x$ and $y$ coordinates. We can add a non-linear smoothing curve to make the general trends a bit more obvious [@baddeleySpatialPointPatterns2015 pp.641].

```{r}
pairs(as.data.frame(pp), panel = panel.smooth, pch=".")
```

We find that the counts of the three genes are very evenly distributed along the $x$ and $y$ coordinate, indicating a homogeneous distribution. The counts of Esr1 and Pgr are positively associated, indicating a dependence of these two marks. 
<!--
The `Smooth` command uses cross-validation to select the smoothing bandwidth of the Gaussian kernel. This estimated kernel can be used for visual inspection of the dataset.

```{r}
ppsmooth <- Smooth(pp, bw.smoothppp)
plot(ppsmooth)
```
From the estimated intensity plot, we can see that the expression of the marker genes is clearly inhomogeneous. [MR: what does it mean that marker gene expression is inhomogeneous .. I thought inhomogeneity had to do with the location of points?!]
-->

NN interpolations uses the nearest mark to measure the intensity at each spatial location. This is conceptually similar to taking a very small bandwidth for Gaussian kernel smoothing [@baddeleySpatialPointPatterns2015 pp. 642]. 

```{r}
plot(nnmark(pp))
```

We see that there is e.g. a clear spatial structure in the expression of e.g. `Esr1`. It shows a half moon shape.
<!--
We can use the average value of neighbouring points to predict the expression of a gene at each point. We can then plot the actual marks versus the fitted values to detect anomalies. For example, `Esr1` shows a clear half moon shape in the middle of the image, where the actual values are much higher than the fitted. This gives further indication of structure in the gene expression.[MR: I don't really understand the interpretation here.]


```{r}
mfit <- Smooth(pp, bw.smoothppp, at="points")
res <- marks(pp) - mfit

plot(setmarks(pp, res))
```

[MR: I don't really have a good intuition of what these plots mean, but I think the plots are anyways hard to interpret. The scale is a bit weird .. I think the point size has some meaning, but that's really hard to see. Colours would be better, but I'm not even sure these plots tell us much interesting. Also, since we are taking differences between values and a smooth fit, the scale of the data becomes important; are we on a "good" scale?]
-->

## Summary functions for continuous marks

As in the discrete case, summary functions assume that the point process is stationary.

### Mark correlation function

The mark correlation function measures the dependence between two marks for two points at distance $r$. It is applicable to stationary point processes with marks. It is not a correlation in the classical sense, since it cannot take negative values [MR: was this a typo? is this correct?]. Instead, a value of 1 indicates no correlation between the marks [MR: does this mean that negative correlation is not allowed? Or, would it appear as 'less than 1'?]. The generalized mark correlation function is given by:

$$ k_f(r) = \frac{\mathbb{E}[f(m(u),m(v))]}{\mathbb{E}[f(M,M')]},$$
where $f(m_1,m_2)$ is a test function with two arguments (representing the two marks) and returns a non-negative value [MR: what are $u$ and $v$ in the formula above?]. For continuous non-negative marks, the canonical choice for $f$ is typically  $f(m_1,m_2)= m_1 m_2$. $M$ and $Mâ€²$ represent independent, identically distributed random points with the same distribution as the mark of a randomly chosen point. This denominator is chosen such that random marks have a mark correlation of 1 [@baddeleySpatialPointPatterns2015 pp. 644-645].

```{r}
plotMetric(plot_by = genes,  pp = pp, x = 'r', fun = 'markcorr', edgecorr = 'iso', continuous = TRUE)
```

From this plot we show that all genes show a positive correlation at small distances which decline with increasing radius $r$. The association is strongest for the Slc18a2 gene. We can calculate simulation envelopes to estimate the significance of this association. This is not shown for brevity.

### Mark-weighted $K$-function

The mark-weigthed $K$-function is a generalization of the $K$-function in which the contribution from each pair of points is weighted by a function of their respective marks. It is given by:

$$K_f(r) = \frac 1  \lambda \frac{C_f(r)}{E[ f(M_1, M_2) ]},$$
where:

$$ C_f(r) = E \left[ \sum_{x \in X} f(m(u), m(x)) 1\{0 < ||u - x|| \le r\} \;  \big| \; u \in X \right], $$ 

is equivalent to the unnormalized mark-weighted $K$-function. For every point $u$, we sum the euclidean distance $||u - x||$ of all other points $x$ that are within a distance $r$. This sum is weighted by the function $f(.,.)$ of the marks of $u$ and $x$. The function is standardized by the expected value of $f(M_1, M_2)$ where $M_1, M_2$ represent independent, identically distributed random points with the same distribution as the mark of a randomly chosen point [@baddeleySpatialPointPatterns2015 pp. 646-647].

In the scenario of random labeling, so where the labels or in this case marks are distributed randomly, the mark-weighted $K$-function corresponds to the standard Ripley's $K$-function.    

Also here, the canonical function is: $f(m_1, m_2) = m_1 m_2$. This means we weigh each interaction between points by the product of the continuous marks of both points.

```{r}
plotMetric(plot_by = genes,  pp = pp, x = 'r', fun = 'Kmark', edgecorr = 'iso', continuous = TRUE, f = function(m1,m2){m1*m2})
```

It is important to note that the theoretical value of the $K$-function is not very informative since it represents the $K$-function of a Poisson point process and the underlying point process might not be Poisson. Therefore we compare the mark-weighted with its unmarked analogue. Like this, we can assess whether the points weighted by a continuous mark are more or less correlated than their unmarked analogues [@baddeleySpatialPointPatterns2015 pp. 647].

Here we will compare the $L$-functions weighted by the mark of the gene Esr1 and the unmarked $L$-function. 

```{r}
ppEsr1 <- subset(pp, select = 'Esr1')
L.Esr1L <- Kmark(ppEsr1, function(m1,m2) {m1*m2}, returnL = TRUE)
Lest.ppEsr1 <- Lest(ppEsr1, nlarge=7000)
plot(eval.fv(L.Esr1L - Lest.ppEsr1))
```

We note that the difference between $L$-function weighted by the expression of Esr1 minus the unmarked $L$-function is positively different to the poisson difference, meaning that the expression of the continuous mark Esr1 is correlated among itself. 


# Summary

In this chapter we have looked at point pattern methods that can be applied to univariate marks. These univariate marks can either be discrete (in a molecular biological context that could be celltypes) or continuous (e.g. expression of a gene). There are approaches that summarise correlative dependencies among points or that consider spacing functions.

# figures for draft

```{r, eval = FALSE}
pls <- lapply(zstack_list, function(zstack){
  pp_sel <- pp_ls[[zstack]][[celltype_ls]]
  p <- pp_sel |> as.data.frame() |> 
  ggplot(aes(x = x, y = y)) +
  geom_point(color = "black", alpha = 0.3) +
  theme_light() +
  coord_fixed() +
  ggtitle(zstack) + 
  theme(legend.position = 'none')
  return(p)
})

p1 <- wrap_plots(pls, guides = 'collect', nrow = 3)
p_K_homo <- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r','Kest', 'iso', bootstrap = TRUE)
p_K_inhomo <- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r','Kinhom', 'iso', bootstrap = TRUE)
p_K_scaled <- plotMetric(plot_by = zstack_list, pp, celltype_ls,'r','Kscaled', 'iso', bootstrap = FALSE)

p2 <- wrap_plots(list(p_K_homo, p_K_inhomo, p_K_scaled), ncol = 3, guides = 'collect')
p_total <- wrap_plots(list(p1, L_plot), ncol = 2) + plot_annotation(tag_levels = 'A')

ggsave('pp_example.pdf', plot = p_total, width = 8, height = 9)
```
# Appendix

## Session info

```{r, cache=FALSE}
#| label: session-info
sessionInfo()
```
