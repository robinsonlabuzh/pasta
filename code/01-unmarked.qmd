---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Preamble

## Dependencies

```{r, cache=FALSE}
#| label: load-libs
#| message: false
#| warning: false
#| results: hide
source("utils.R")
```

## Setup

```{r, cache=FALSE}
#| label: load-data
spe <- readRDS("../data/spe.rds")

#subset the data to only look at sample ID 0.01
sub <- spe[, spe$sample_id == 0.01]
(pp <- .ppp(sub, marks = "cluster_id"))

#split the multitype point process into single types
#first, set the marks of the point process to be factors
marks(pp) <- factor(marks(pp))
ppls <- split(pp)
```

To set the situation, we first visualize the annotated cell types in their original spatial context:

```{r, fig.width=12, fig.height=12, cache=FALSE}
#Plot the marks separately for selected subpopulations
# selected <- c("OD Mature", "Microglia", "Ependymal")
plot(ppls, main = 'Subpopulations')
``` 


## Concepts and Definitions of Point Processes

<!-- ### Point Process -->

<!-- ```{r} -->

<!-- ``` -->

### Complete Spatial Randomness

Complete spatial randomness (CSR) is the typical null model used for point patterns, being the result of a Poisson process. A completely random process is characterised by two properties, homoegeneity and independence.

#### Homogeneity

Homogeneity means that the expected number of points falling into a given region $B$ is proportional to its area $|B|$ given a proportionality constant $\lambda$. The constant $\lambda$ is the intensity of the process, so the average number of points in a unit area is defined by:

$$
\mathbb{E}[X\cap B] = \lambda |B|
\label{eq:expected_number_points}.
$$

#### Independence

Independence means that in two regions, $A$ and $B$, the number of points $n(X\cap A)$ and $n(X\cap B)$ are two independent random variables. That means the number of points in region $A$ does not affect the number of points in region $B$. The number of points follow a Poisson distribution:

$$
\mathbb{P}[N=k] = e^{-\mu}\frac{\mu^k}{k!}\\
\label{eq:Poisson_process}.
$$
<!-- [should we write the above as:  -->
<!-- \mathbb{P}[n(X\cap A)=k] = e^{-\lambda |B|}\frac{(\lambda |B|)^k}{k!}\\] -->

### Inhomogeneous Poisson Process

In contrast to CSR, a Poisson process that is spatially varying in its average density of points is called inhomogeneous. Here, the density $\lambda(u)$ is a function of spatial location $u$. The expected number of points falling into a region $B$ is then:

$$
\mu = \int_{B} \lambda(u)du 
\label{eq:expected_number_inhomogeneous}.
$$

### Isotropy and Stationarity

"A point process is called stationary if, when we view the process through a window $W$, its statistical properties do not depend on the location of the window in two-dimensional space." [citation]. A point process is called isotropic, if its statistical properties are invariant to rotations. A CSR process is both stationary and isotropic.


#### Correlation stationarity

It is important to note that the inhomogeneous K-function [MR: we have not defined the K-function up to this point] does not apply to every spatially inhomogeneous point process. It only applies to point processes that are correlation stationary. A point pattern is correlation stationary if the pair correlation function only depends on the relative position in subpatterns of the point process, which means that estimates of the inhomogeneous K-function should be similar in different subquadrats of the point pattern. 

### Local scaling

The inhomogeneous K-function further assumes that while the intensity is spatially varying, the scale of the interaction remains constant. This is equivalent to the assumption that in small subregions, the process is stationary and isotropic, but the rescaling factor can vary across the total process. In this case, the locally scaled version of the K-function is applicable.

Furthermore, we can use a permutation test to test the inhomogeneity assumption. In this scenario, we split the patterns into quadrats and compare the estimatied functions between the quadrats. It has to be noted that this test highly depends on the definition of the quadrats.

```{r}
selection <- c('OD Mature')
pp_sel <-  subset(pp, marks %in% selection, drop = TRUE)


odrho <- rhohat(unmark(pp_sel), "x", method="tr")
odlambda <- predict(odrho)

od4 <- quantess(unmark(pp_sel), "x", 2)
od42 <- nestsplit(pp_sel, od4, ny=3)

plot(od42)

od42$inten <- factor(as.integer(od42$f1) <= 1, labels=c("Hi","Lo"))

studpermu.test(od42, pts ~ inten, summaryfunction=Kscaled,
               minpoints = 10)

studpermu.test(od42, pts~ inten, summaryfunction=Kinhom,
               lambda=odlambda, minpoints = 10)
```

Alternatively, we can inspect deviations against the hypothesis that the points were generated by a Poisson process. We can identify hotspots and coldspots by comparing the standard error of the `relrisk` function, which computes nonparamatric estimates of the relative risk by kernel smoothing, to the theoretical null distribution of points. The relative risk is the ratio of spatially varying probablilities of different types.

[Source](https://idblr.rbind.io/post/pvalues-spatial-segregation/)

```{r, eval=FALSE}
#Code source: https://idblr.rbind.io/post/pvalues-spatial-segregation/

f1 <- rp
# Significant p-values assumming normality of the Poisson process
## relrisk() computes standard errors based on asymptotic theory, assuming a Poisson process
  alpha <- 0.05                           # alpha
  z <- qnorm(alpha/2, lower.tail = F)     # z-statistic
  f1$u <- f1$estimate + z*f1$SE           # Upper CIs
  f1$l <- f1$estimate - z*f1$SE           # Lower CIs
  mu_0 <- as.vector(table(spatstat.geom::marks(pp))/pp$n) # null expectations by type
  f1$p <- f1$estimate # copy structure of pixels, replace values
  for (i in 1:length(f1$p)) {
    f1$p[[i]]$v <- factor(ifelse(mu_0[i] > f1$u[[i]]$v, "lower",
                                 ifelse( mu_0[i] < f1$l[[i]]$v, "higher", "none")),
                          levels = c("lower", "none", "higher"))
  }

# Plot significant p-values
plot(f1$p, main = "Significant difference\n to Poisson process alpha = 0.05")
```

<!-- 
```{r}
selection <- c('Ependymal')
pp_sel <-  subset(pp, marks %in% selection, drop = TRUE)


odrho <- rhohat(unmark(pp_sel), "x", method="tr")
odlambda <- predict(odrho)

od4 <- quantess(unmark(pp_sel), "x", 2)
od42 <- nestsplit(pp_sel, od4, ny=3)

plot(od42)

od42$inten <- factor(as.integer(od42$f1) <= 1, labels=c("Hi","Lo"))

studpermu.test(od42, pts ~ inten, summaryfunction=Kscaled, minpoints = 10)

studpermu.test(od42, pts~ inten, summaryfunction=Kinhom,
               lambda=odlambda, minpoints = 10)
``` 
-->

### Intensity

Intensity is the expected density of points per unit area, as seen above. It can be interpreted as the rate of occurrence or the abundance of events recorded. The intensity itself is called a first moment property - being related to the expected number of points.

#### Estimating Intensity

The intensity can be estimated regardless of the type of the point pattern. In order to do so, we sum the individual intensities of the marks

```{r, cache=FALSE}
intensityPointProcess<- function(pp,mark){
  if(mark == TRUE){
    return(intensity(pp))
  }
  else{
    return(sum(intensity(pp)))
  }
}

intensityPointProcess(pp,mark=FALSE)
```

else we can look at each mark individually

```{r, cache=FALSE}
intensityPointProcess(pp,mark=TRUE)
```
#### Quadrat Counting

In quadrat counting all the points falling into a given quadrat are counted. This gives an overview on the characeterstics of the point pattern, such as correlation stationarity.

```{r, fig.width=12, fig.height=12, cache=FALSE}
Q5 <- quadratcount(pp, nx=5, ny=5)
plot(unmark(pp), main='Unmarked Point Pattern Quadrats')
plot(Q5, col='black', add=TRUE)
```

<!-- or for each type separately, treating each type as an unmarked process

```{r, fig.width=12, fig.height=12, cache=FALSE}
Q5sep <- quadratcount(ppls, nx=5, ny=5)
plot(Q5sep, main = 'Separated Marks Quadrats')
#plot(ppls, add=TRUE)
``` 
-->

The quadrat counts can be tested against regularity. This can happen again in the unmarked pattern or in the separated types. This tells us if the counts of the points are distributed evenly across the quadrats.

```{r, cache=FALSE}
quadratTestPointProcess <- function(pp, mark){
  if(mark==TRUE){
    return(lapply(split(pp), quadrat.test, 5, alternative="regular", method="MonteCarlo"))
  }
  else{
    return(quadrat.test(unmark(pp), 5, alternative="regular", method="MonteCarlo"))
  }
}
quadratTestPointProcess(pp, mark=FALSE)
```

#### Kernel Estimation

In kernel estimation we try to estimate the intensity function $\lambda(u)$ of the point process. There are different types of kernel estimators (see Baddeley). A popular choice is the isotropic Gaussian kernel where the standard deviation corresponds to the smoothing bandwidth.

```{r, fig.width=12, fig.height=12, cache=FALSE}
Dens <- density(pp)
plot(Dens, main = 'Kernel Density')
```

<!-- 

```{r, fig.width=12, fig.height=12, cache=FALSE}
Denssep <- density(ppls)
plot(Denssep, main = 'Kernel Density Separated Marks  ')
``` 


### Summarising Functionality for Estimating Intensity - unfinished

```{r, eval=FALSE, cache=FALSE}
#PRE:
#POST:
estimatingIntensity <- function(
  pp
  method = c('expectation', 'quadrat', 'kernel', 'density', 'adaptive-density'),
  homogeneous = FALSE,
  nx = NULL,
  ny = NULL,
  correction = c(),
){

}
```
-->

### Testing for CSR

Whether or not a point process is completely spatially random depends on two characeteristics. The points have to be distributed homogeneously and they have to be independent of each other (see definitions above). There are different ways to test for CSR which are summarised in the wrapper below.

```{r, cache=FALSE}
#PRE: takes a point process and the indication, which test for CSR should be performed and potentially a covariate
#POST: returns if a point process or its individual point process marks are CSR or not.
#TODO: Change maybe to a switch statment in terms of computing time; Change lapply to mclapply later on
#TODO: There is a conceptual mistake - we pull out marks and test them against a markov simulation. It should rather be to test against all the other cells
testingCSR <- function(
    pp,
    method = c('quadrat','cdf','bermans','clark-evans','hopkins-skellam'),
    mark = FALSE,
    covariate = NULL,
    test = c('ks', 'cvm', 'ad'),
    verbose = FALSE
){
  #perform a quadrattest for individual marks or for the entire pointprocess
  if(method == 'quadrat'){
    if(mark == TRUE){
      test.result <- lapply(split(pp), quadrat.test, 5, method="MonteCarlo")
    }
    else{
      test.result <- quadrat.test(unmark(pp), 5, method="MonteCarlo")
    }
   }
  #perform a cdftest for individual marks or for the entire pointprocess given a covariate
  else if(method == 'cdf' && !is.null(covariate)){
    if(mark == TRUE){
      test.result <- lapply(split(pp), cdf.test, covariate, test=test)
    }
    else{
      test.result <- cdf.test(unmark(pp), covariate, test=test)
    }
  }
  #perform a bermans test for individual marks or for the entire pointprocess
  else if(method == 'bermans' && !is.null(covariate)){
     if(mark == TRUE){
      test.result <- lapply(split(pp), berman.test, covariate, test='Z1')
    }
    else{
      test.result <- berman.test(unmark(pp), covariate, test='Z1')
    } 
  }
  #perform a clark evans test for individual marks or for the entire pointprocess
  else if(method == 'clark-evans'){
     if(mark == TRUE){
      test.result <- lapply(split(pp), clarkevans.test)
    }
    else{
      test.result <- clarkevans.test(unmark(pp))
    } 
  }
  #perform a hopkins-skellam test for individual marks or for the entire pointprocess
  else if(method == 'hopkins-skellam'){
     if(mark == TRUE){
      test.result <- lapply(split(pp), hopskel.test)
    }
    else{
      test.result <- hopskel.test(unmark(pp))
    } 
  }
  #base case of the "switch" statement
  else{
    print("ERROR: non-specified arguments or methods")
    return(NULL)
  }
  
  #summarise the results as a mask of booleans to indicate which structures are 
  #random and which are not
  if(mark==TRUE){
    p.value.mask <- lapply(test.result, function(x) x$p.value>0.05)
  }
  else{
    p.value.mask <- test.result$p.value>0.05
  }
  #return the values of the test calculations, either just the boolean if 
  #CSR or not or the entire test statistics
  if(verbose == TRUE){
    return(test.result)
  }
  else{
    return(p.value.mask)
  }
}
result <- testingCSR(pp,method='clark-evans',mark=TRUE, verbose=FALSE)

testingCSR(ppls$Ependymal, method='clark-evans')
testingCSR(ppls$`OD Mature`, method='clark-evans')
testingCSR(ppls$Microglia, method='clark-evans')
```

## Correlation

Correlation or more generally covariance is called a second order quantity and measures dependence between data points. This is a very useful concept, allowing for the assessment of correlation between points.

<!-- 
### Morisita Index

$$
M = m \frac{\sum_jn_j(n_j-1)}{n(n-1)}
$$

where we subdivide the point process into $m$ quadrats. The formula above is called the Morisita index which is the ratio of observed and expected fractions. If the points are independent the Morisita index is close to 1, greater than 1 if they are clustered, and less than 1 if they are regular. This concept is closely linked to the index of dispersion (in fact with a bit of algebra, these two can be transformed into each other)

$$
I = \frac{s^2}{\bar{n}} = \frac{m}{n(m-1)}\sum_{j=1}^m\left(n_j-\frac{n}{m}\right)^2
$$

```{r, cache=FALSE}
miplot(ppls$Ependymal)
miplot(ppls$`OD Mature`)
miplot(ppls$Microglia)
```

### Fry plot

A fryplot is a scatterplot of the vector differences $x_j-x_i$ between all paris of distinct points in the pattern.

```{r, cache=FALSE}
fryplot(ppls$Ependymal)
fryplot(ppls$`OD Mature`)
fryplot(ppls$Microglia)
``` 
-->

### Ripley's $K$

#### Empirical Ripley's $K$

In the framework of correlation analysis we often look at distances $d_{ij} = ||x_i-x_j||$ of all ordered points. It is a natural idea to look at the summary of these distances $d_{ij}$, e.g. a histogram. The histogram of this point process is a difficult statistic, as it depends on the observation window $W$, thus the histogram can change significantly with a changing window $W$. Therefore, we look at the empirical distribution function of the distances $d_{ij}$ that are smaller or equal than a radius $r$

$$
\hat{H}(r) = \frac{1}{n(n-1)}\sum_{i=1}^n \sum_{j=1\\j\neq i}^n \{d_{ij}\leq r\}
$$

The contribution of each point $x_i$ to the sum above is

$$
t_i(r) = \sum_{j \neq i} \mathbb{1} \{d_{ij}\leq r\}
$$

this number $t_i(r)$ is the number of points that fall within a radius $r$ centered at $x_i$. It follows then:

$$
\hat{H}(r) = \frac{1}{n(n-1)}\sum_{i=1}^n t_i(r) = \frac{1}{n-1} \bar{t}(r)
$$

Here, we see what we actually want to measure is "the average number of r-neighbours of a typical random point". This number is still dependent on the size of the observation window so we want to standardise is by the number of points and $|W|$ the window size. Then we obtain the empirical Ripley's $K$ function

$$
\hat{K}(r) = \frac{|W|}{n(n-1)}\sum_{i=1}^n\sum_{j=1 \\j \neq i}^n\{d_{ij}\leq r\}
$$

The standardisation makes it possible to compare point patterns with different observation windows and with different numbers of points. Using the empirical $K$ function assumes though tha the point process has homogeneous intensity. 


#### True $K$-function

instead of the summary of pairwise distances, we are interested in the point process. In order to do so, we have to think about the expected number of $r$-neighbours given a point $X$ at a location $u$ divided by its intensity $\lambda$

This means

$$
K(r) = \frac{1}{\lambda} \mathbb{E} [t(u,r,X)|u \in X]
$$

where

$$
t(u,r,X) = \sum_{j=1}^{n(X)} \mathbb{1} \{0<||u-x_j||\leq r\}
$$

This definition of the true $K$ function is only valid if the point process is stationary. For a homogeneous Poisson process we obtain

$$
K_{pois}(r) = \pi r^2
$$

#### Edge effects and their corrections for spatial metrics

Edge effects describe the phenomenon that we never observe the entire point process but only a part of it within a window $W$. This means that parts of the point process at the border might not be observed and the value of the statistic biased along the edges.

There are many corrections for edge effects. They are briefly listed here

##### Border correction

In border correction the summation of data points is restricted to $x_i$ for which $b(x_i,r)$ is completely in the window $W$.

##### Isotropic correction

We can regard edge effect as a sampling bias. Larger distances (e.g. close to the edges) are less likely to be observed. This can be corrected for.

##### Translation correction

A stationary point process $X$ is invariant to translations. So the entire point process can be shifted by a vector $s$ to be at the position $X+s$. 

### The $L$-function

The $K$-function can be centered which is then called the $L$-function. The $L$-function is a variance-stabilising version of the $K$-function (see spicyR for reference).

$$
L(r) = \sqrt{\frac{K(r)}{\pi}}
$$

### Pair Correlation function

We have seen above, that the $K$-function is cumulative in nature. Meaning that the contributions of all distances smaller equal to $r$ are counted. An alternative is to take the derivative of the $K$-function in order to obtain contributions of distances between points equal to $r$. 

$$
g(r) = \frac{K'(r)}{2\pi r}
$$

"$g(r)$ is the probability of observing a pair of point of the process separated by a distance $r$, divided by the corresponding probability for a Poisson process."

#### Estimator of the pair correlation function

The pair correlation function can be estimated via kernel smoothing. In very large datasets the pair correlation function can be approximated using histogram-based methods. 

$$
\hat{g}(r) = \frac{|W|}{2 \pi r n (n-1)} \sum_{i=1}^n\sum_{j=1 \\j \neq i}^n \kappa_h(r-d_{ij})e_{ij}(r)
$$

where $\kappa$ is the smoothing kernel. $\kappa_h(x)$ is a rescaled version of the template kernel $\kappa$

$$
\kappa_h(x) = \frac{1}{h}\kappa\left(\frac{x}{h}\right)
$$

In the above, $\kappa$ can be any probability density "over the real line with mean 0". Usually, the Epanechinikov kernel is used as smoothing kernel with half-width $w$. 

```{r, cache=FALSE}
K_ependymal <- lohboot(ppls$Ependymal, fun='Kest')
K_ependymal$type <- 'Ependymal'

K_odmature <- lohboot(ppls$`OD Mature`, fun='Kest')
K_odmature$type <- 'OD Mature'

K_microglia <- lohboot(ppls$Microglia, fun='Kest')
K_microglia$type <- 'Microglia'

#create a list that combines bove values
K_list <- rbind(K_ependymal, K_odmature, K_microglia)

p_K <- ggplot(K_list, aes(x=r, y=iso, col= type))+
  geom_line()+
  geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+
  ggtitle('estimated K-function')+
  geom_line(aes(x=r,y=theo),col = 'black',linetype = "dashed")+
  theme_light()

L_ependymal <- lohboot(ppls$Ependymal, fun='Lest')
L_ependymal$type <- 'Ependymal'

L_odmature <- lohboot(ppls$`OD Mature`, fun='Lest')
L_odmature$type <- 'OD Mature'

L_microglia <- lohboot(ppls$Microglia, fun='Lest')
L_microglia$type <- 'Microglia'

#create a list that combines bove values
L_list <- rbind(L_ependymal, L_odmature, L_microglia)

p_L <- ggplot(L_list, aes(x=r, y=iso, col= type))+
  geom_line()+
  geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+
  ggtitle('estimated L-function')+
  geom_line(aes(x=r,y=theo),col = 'black',linetype = "dashed")+
  theme_light()

g_ependymal <- lohboot(ppls$Ependymal, fun='pcf')
g_ependymal$type <- 'Ependymal'

g_odmature <- lohboot(ppls$`OD Mature`, fun='pcf')
g_odmature$type <- 'OD Mature'

g_microglia <- lohboot(ppls$Microglia, fun='pcf')
g_microglia$type <- 'Microglia'

#create a list that combines bove values
g_list <- rbind(g_ependymal, g_odmature, g_microglia)

p_g <- ggplot(g_list, aes(x=r, y=border, col= type))+
  geom_line()+
  geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+
  ggtitle('pcf-function')+
  geom_line(aes(x=r,y=theo),col = 'black',linetype = "dashed")+
  theme_light()
```

```{r, cache=FALSE, fig.height = 10, fig.width = 7}
p_K/p_L/p_g
```

### Correcting for Inhomogeneity

#### Inhomogeneous $K$-function

In the case that a spatial pattern is known or suspected to be inhomogeneous, we have to take this into account for our analysis. Biological samples display inhomogeneity very often, therefore this analysis is preferred over the homogeneous alternatives. Inhomogeneous alternatives can be calculated via:

$$
K_{inhom}(r) = \mathbb{E} \left[\sum_{x_j \in X} \frac{1}{\lambda(x_j)}\mathbb{1}\{0<||u-x_j||\leq r\}|u \in X\right]
$$

This theoretical quantity can be approximated with estimators such as

$$
\hat{K}_{inhom}(r) = \frac{1}{D^p|W|}\sum_i\sum_{j \neq i} \frac{\mathbb{1}\{||u-x_j||\leq r\}}{\hat{\lambda}(x_j)\hat{\lambda}(x_i)}e(x_j,x_i;r)
$$

where $e(u,v;r)$ is an edge correction weight, $\hat{\lambda}(u)$ is an estimator of the intensity of $u$ and $D^p$ is the pth power of 

$$
D = \frac{1}{|W|}\sum_i \frac{1}{\hat{\lambda}(x_i)}
$$

```{r, cache=FALSE}
K_ependymal_inhom <- lohboot(ppls$Ependymal, fun='Kinhom')
K_ependymal_inhom$type <- 'Ependymal'

K_odmature_inhom <- lohboot(ppls$`OD Mature`, fun='Kinhom')
K_odmature_inhom$type <- 'OD Mature'

K_microglia_inhom <- lohboot(ppls$Microglia, fun='Kinhom')
K_microglia_inhom$type <- 'Microglia'

#create a list that combines bove values
K_list_inhom <- rbind(K_ependymal_inhom, K_odmature_inhom, K_microglia_inhom)

p_K <- ggplot(K_list_inhom, aes(x=r, y=iso, col= type))+
  geom_line()+
  geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+
  ggtitle('inhomogeneous K-function')+
  geom_line(aes(x=r,y=theo),col = 'black',linetype = "dashed")+
  theme_light()

L_ependymal_inhom <- lohboot(ppls$Ependymal, fun='Linhom')
L_ependymal_inhom$type <- 'Ependymal'

L_odmature_inhom <- lohboot(ppls$`OD Mature`, fun='Linhom')
L_odmature_inhom$type <- 'OD Mature'

L_microglia_inhom <- lohboot(ppls$Microglia, fun='Linhom')
L_microglia_inhom$type <- 'Microglia'

#create a list that combines bove values
L_list_inhom <- rbind(L_ependymal_inhom, L_odmature_inhom, L_microglia_inhom)

p_L <- ggplot(L_list_inhom, aes(x=r, y=iso, col= type))+
  geom_line()+
  geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+
  ggtitle('inhomogeneous L-function')+
  geom_line(aes(x=r,y=theo),col = 'black',linetype = "dashed")+
  theme_light()

g_ependymal_inhom <- lohboot(ppls$Ependymal, fun='pcfinhom')
g_ependymal_inhom$type <- 'Ependymal'

g_odmature_inhom <- lohboot(ppls$`OD Mature`, fun='pcfinhom')
g_odmature_inhom$type <- 'OD Mature'

g_microglia_inhom <- lohboot(ppls$Microglia, fun='pcfinhom')
g_microglia_inhom$type <- 'Microglia'

#create a list that combines bove values
g_list_inhom <- rbind(g_ependymal_inhom, g_odmature_inhom, g_microglia_inhom)

p_g <- ggplot(g_list_inhom, aes(x=r, y=border, col= type))+
  geom_line()+
  geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25)+
  ggtitle('inhomogeneous pcf-function')+
  geom_line(aes(x=r,y=theo),col = 'black',linetype = "dashed")+
  theme_light()
```

```{r, cache=FALSE, fig.height = 10, fig.width = 7}
p_K/p_L/p_g
```

The inhomogeneous $K$-function tells us that the microglia cells follow a Poisson process (dashed line) closely and can therefore be assumed to be randomly distributed and not clustered. Ependymal cells show a high degree of clustering at a low radius $r$. OD mature cells are in the middle, showing a lower degree of clustering at lower values of $r$.

The $L$-function is a variance stabilised (source spicyR) version of the $K$-function. Thus, the information is complementary to the above. Microglia cells are along the dashed Poisson line, indicating no clustering of microglia cells. Ependymal cells are highly clustered at low values of $r$, whereas OD mature show intermediate clustering at lower values of $r$.

The pair correlation function is the derivative of the $K$-function. Therefore, it is not a sum of the points in the circle with radius $r$ but rather the individual points on the radius $r + h$ where $h$ is very small. The pcf plot gives similar information as before: Microglia cells are around the dashed Poisson line. OD Mature cells show a rather broad range of correlations between $r \in [20,100]$. Ependymal cells have a very strong correlation at $\sim r = 25$. 

We have to note that inhomogeneity correction assumes that the process is correlation stationary, meaning that the summary statistics are the same in each quadrat. This is clearly violated at least for Ependymal cells and OD mature cells. Therefore, the question remains whether acounting for one issue (homogeneity) via a correction that assumes correlation stationarity does not just exchange one problem for another.

### Local Scaling

#### Locally-scaled $K$-function

In the inhomogeneous $K$ approach above we assume that the local scale of the point process is not changed. However, the intensity can vary spatially. In a biological sample this assumption is easily violated, thinking e.g. of a gradient of cells that increases from one side to another. Therefore, we can assume that the process is subdivided in small regions. In these small regions the point process is a scaled version of a template process. This template process has to be both stationary and isotropic. For two locations $u$ and $v$ we would then assume that 

$$
g(u,v) = g_1 \left(\frac{||u-v||}{s}\right)
$$

In this example, $g_1$ is the pair correlation function of the template process and $s$ a scaling factor.

#### Locally-scaled pair-correlation function

would work by taking the derivative of the locally scaled $K$-function 


#### Locally-scaled $L$-function

As the $L$ is just a transformation of the $K$-function, the same local scaling can apply to the $L$-function

```{r}
K_ependymal_scaled <- Kscaled(ppls$Ependymal)
K_ependymal_scaled$type <- 'Ependymal'

K_odmature_scaled <- Kscaled(ppls$`OD Mature`)
K_odmature_scaled$type <- 'OD Mature'

K_microglia_scaled <- Kscaled(ppls$Microglia)
K_microglia_scaled$type <- 'Microglia'

#create a list that combines bove values
K_list_scaled<- rbind(K_ependymal_scaled, K_odmature_scaled, K_microglia_scaled)

p_K <- ggplot(K_list_scaled, aes(x=r, y=iso, col= type))+
  geom_line()+
  ggtitle('Locally scaled K-function')+
  geom_line(aes(x=r,y=theo),col = 'black',linetype = "dashed")+
  theme_light()

L_ependymal_scaled <- Lscaled(ppls$Ependymal)
L_ependymal_scaled$type <- 'Ependymal'

L_odmature_scaled <- Lscaled(ppls$`OD Mature`)
L_odmature_scaled$type <- 'OD Mature'

L_microglia_scaled <- Lscaled(ppls$Microglia)
L_microglia_scaled$type <- 'Microglia'

#create a list that combines bove values
L_list_scaled<- rbind(L_ependymal_scaled, L_odmature_scaled, L_microglia_scaled)

p_L <- ggplot(L_list_scaled, aes(x=r, y=iso, col= type))+
  geom_line()+
  ggtitle('Locally scaled L-function')+
  geom_line(aes(x=r,y=theo),col = 'black',linetype = "dashed")+
  theme_light()
```


```{r, cache=FALSE, fig.height = 10, fig.width = 7}
p_K/p_L
```

The interpretation of the locally scaled $L$-function is similar to the interpreation of the inhomogeneous $L$-function. The correlation is strongest for Ependymal cells, followed by OD mature cells. Microglia cells are again close to the random Poisson process. Note that here, the curves of the Ependymal and OD mature cells stay always above the dashed Poisson line, unlike in the inhomogeneous version. 

Given that our biological samples are both inhomogeneous and locally scaled by eye (can be tested as seen above), the locally scaled $L$-function seems a good variant for assessing correlation. 

#### Local Indicators of Spatial Association

The $K$ and $L$-functions above are summary statistics over the entire pattern. However, if we know that there are different regions in our point pattern, we might want to know the individual contributions of these patterns. This gives then e.g. $n$ (for all points) local $K$,$L$ or pair correlation-functions. Baddley et. al. propose to compare these $n$ functions with e.g. functional principal component analysis. We will show here the example of the LISA version of the $L$ function.

<!-- ##### Local $K$ function

```{r}
K_ependymal_lisa <- localK(ppls$Ependymal)
plot(K_ependymal_lisa, main = 'local K functions Ependymal', legend=FALSE)

K_odmature_lisa <- localK(ppls$`OD Mature`)
plot(K_odmature_lisa, main = 'local K functions OD Mature', legend=FALSE)

K_microglia_lisa <- localK(ppls$Microglia)
plot(K_microglia_lisa, main = 'local K functions Microglia', legend=FALSE)
```

##### Local pair correlation function

```{r}
g_ependymal_lisa <- localpcf(ppls$Ependymal)
plot(g_ependymal_lisa, main = 'local pcf functions Ependymal', legend=FALSE)

g_odmature_lisa <- localpcf(ppls$`OD Mature`)
plot(g_odmature_lisa, main = 'local pcf functions OD Mature', legend=FALSE)

g_microglia_lisa <- localpcf(ppls$Microglia)
plot(g_microglia_lisa, main = 'local pcf functions Microglia', legend=FALSE)
``` 
-->

##### Local $L$ function

```{r}
# L_ependymal_lisa <- localL(ppls$Ependymal)
# plot(L_ependymal_lisa, main = 'local L functions Ependymal', legend=FALSE)

L_odmature_lisa <- localL(ppls$`OD Mature`)
plot(L_odmature_lisa, main = 'local L functions OD Mature', legend=FALSE)

# L_microglia_lisa <- localL(ppls$Microglia)
# plot(L_microglia_lisa, main = 'local L functions Microglia', legend=FALSE)
```

In the case of the OD mature cells we obtain further information with this plot. We note that there are two distinct populations of curves, those that are clearly above the straight Poisson line and others that are around/underneath the straight Poisson line. This indicates that there are two different kinds of interactions in the OD mature cells. Stronger clustering (the upper part of the plot) and more random parts (lower part).

There are inhomogeneous versions of these (e.g. `localLinhom`). These are not shown here for brevity.

##### Functional PCA for the $n$ Curves

We apply functional PCA to retrieve the main trends in these individual curves. The idea of functional PCA is the same as for ordinary PCA just applied to the concept of functions. For the $n$ functions above functional PCA will recover the main trends in the data

```{r}
#adapted from the fdapace vignette
functional.pca.pp <- function(df){
  df_fdob <- df %>% as.matrix()
  #remove theo column - we want only the actual estimations in there without the Poisson line theo
  df_fdob <- df_fdob[,-ncol(df_fdob)]
  #remove r column - this has to be provided independently to the FPCA - this is the yVec
  df_fdob <- df_fdob[,-ncol(df_fdob)]
  #number of columns
  N <- ncol(df_fdob)
  #number of rows
  M <- nrow(df_fdob)
  #the x values at which all the curves were evaluated, here called tVec
  s <- df$r
  #create the FPCA object
  fd_obj <- fdapace::MakeFPCAInputs(IDs = rep(1:N, each=M),tVec=rep(s,N), yVec=df_fdob)
  #check that the FPCA object is valid
  fdapace::CheckData(fd_obj$Ly, fd_obj$Lt)
  #run the computation of the FPCA - would work with sparse data.
  fpca_obj <- fdapace::FPCA(fd_obj$Ly, fd_obj$Lt, list(plot = TRUE, dataType='Dense', kernel='rect'))
  fdapace::CreateModeOfVarPlot(fpca_obj, title = 'Modes of Variation OD Mature cells')
}

# #first for the K functions
# functional.pca.pp(K_ependymal_lisa)
# functional.pca.pp(K_odmature_lisa)
# functional.pca.pp(K_microglia_lisa)

# #g functions
# functional.pca.pp(g_ependymal_lisa)
# functional.pca.pp(g_odmature_lisa)
# functional.pca.pp(g_microglia_lisa)

#L functions
#functional.pca.pp(L_ependymal_lisa)
functional.pca.pp(L_odmature_lisa)
#functional.pca.pp(L_microglia_lisa)
```

Here, we see the functional PCA for the OD mature cells. The Design plot tells us that we have a very dense dataset over the entire support. The mean curve displays the mean trend over all $n$ LISA $L$-curves (note that this result is similar to the locally scaled $L$-function). The scree plot indicates that the first eigenfunction explains more than $80 \%$ of the variance. The eigenfunction curves in the bottom right panel indicate the deviation from the mean curve.

As such it is natural to display the eigenfunction as their contribution to the deviation around the mean as a confidence ribbon. The patterns in variation of the point process are captured in the mode of variation plot. The modes of variation capture the contribution of the first (in this case two) eigenfunctions around the mean. -> check the source from the Springer book "Functional Data Analysis with R and Matlab".

### Third-Order Summary Statistics

So far we have considered first- and second-order summary statistics and local adaptations of these. In the following, we will continue a high-order statistics. In second-order statistics one considers pairs and counts these in the case of the $K$ function. In a third-order setting we would now count triplets of points. A triplet is counted as the normalised expected value of triangles where all edges are smaller than the radius r

$$
T(r) = \frac{1}{\lambda^3}\mathbb{E}\left[\sum_{i=1}^n\sum_{j=1\\j\neq i}^nm(x_i,x_j,u) | u \in X\right]
$$

here m is the maximum side of the triangle

$$
m(a,b,c) = \max(||a-b||,||a-c||,||b-c||)
$$

```{r}
T_ependymal <- Tstat(ppls$Ependymal)
T_ependymal $type <- 'Ependymal'

T_odmature <- Tstat(ppls$`OD Mature`)
T_odmature$type <- 'OD Mature'

T_microglia <- Tstat(ppls$Microglia)
T_microglia$type <- 'Microglia'

#create a list that combines bove values
T_list<- rbind(T_ependymal, T_odmature, T_microglia)

p <- ggplot(T_list, aes(x=r, y=trans, col= type))+
  geom_line()+
  ggtitle('Third-order summary statistic')+
  geom_line(aes(x=r,y=theo),col = 'black',linetype = "dashed")+
  theme_light()
p
```

#### DBSCAN

 Here we show one very basic approach, DBScan (density-based spatial clustering with applications for noise)

```{r, cache=FALSE}
pp_df <- as.data.frame(ppls$`OD Mature`)
#determine the correct epsilon neighbourhood
dbscan::kNNdistplot(pp_df, k=5)
```

Given the kNN distance plot we visually detect the "knee" of the curve to be at an distance $\epsilon$ of $50$. This value is needed for the computation of DBScan.

```{r}
#perform DBScan
pp_dbscan <- dbscan::dbscan(pp_df[-3], eps =50, minPts = 5)
plot(pp_df[-3], col = pp_dbscan$cluster)

# pp_df <- as.data.frame(ppls$Ependymal)
# #determine the correct epsilon neighbourhood
# dbscan::kNNdistplot(pp_df, k=5)
# #perform DBScan
# pp_dbscan <- dbscan::dbscan(pp_df[-3], eps =75, minPts = 5)
# plot(pp_df[-3], col = pp_dbscan$cluster)

# pp_df <- as.data.frame(ppls$Microglia)
# #determine the correct epsilon neighbourhood
# dbscan::kNNdistplot(pp_df, k=5)
# #perform DBScan
# pp_dbscan <- dbscan::dbscan(pp_df[-3], eps =100, minPts = 5)
# plot(pp_df[-3], col = pp_dbscan$cluster)

# pp_df <- as.data.frame(ppls$Inhibitory)
# #determine the correct epsilon neighbourhood
# dbscan::kNNdistplot(pp_df, k=5)
# #perform DBScan
# pp_dbscan <- dbscan::dbscan(pp_df[-3], eps =60, minPts = 5)
# plot(pp_df[-3], col = pp_dbscan$cluster)

# pp_df <- as.data.frame(ppls$Excitatory)
# #determine the correct epsilon neighbourhood
# dbscan::kNNdistplot(pp_df, k=5)
# #perform DBScan
# pp_dbscan <- dbscan::dbscan(pp_df[-3], eps =75, minPts = 5)
# plot(pp_df[-3], col = pp_dbscan$cluster)

# pp_df <- as.data.frame(ppls$Pericytes)
# #determine the correct epsilon neighbourhood
# dbscan::kNNdistplot(pp_df, k=5)
# #perform DBScan
# pp_dbscan <- dbscan::dbscan(pp_df[-3], eps =50, minPts = 5)
# plot(pp_df[-3], col = pp_dbscan$cluster)
```

another lead to follow in detected spatial clusters is scan statistics with the \texttt{R} package \texttt{rflexscan}.

## Spacing

So far, most approaches considered intensity and correlation as measures to assess a point pattern. In the following chapter we will look at measures of spacing and shortest-distances to assess spatial arrangements.

Baddeley et.al. summarises three basic distances to measure

- pairwise distance: $d_{i,j} = ||x_i-x_j||$
- nearest-neighbour distances: $d_i = \min_{j \neq i}d_{ij}$
- empty-space distance: $d(u) = \min_j||u-x_j||$

There are test of CSR that are based on spacing -> Clark-Evans test and Hopkins-Skellam Index that are both implemented above in the CSR testing function

<!-- ### Exploratory Graphics

#### Stienen Diagram

The stienen diagram is obtained by drawing circles around each point in the process of the size of its nearest neighbour distance

```{r}
stienen(ppls$Ependymal)
stienen(ppls$`OD Mature`)
stienen(ppls$Microglia)
```

#### Dirichlet Tiles

Dirichlet tiles are considered as the space "that is closer to $x_i$ than to any other point in the pattern $x$:"

$$
C(x_i|x) = \{u \in \mathbb{R}^2:||u-x_i|| = \min_{j} ||u-x_j||\}
$$

These dirichlet tiles are convex polygons

```{r}
plot(dirichlet(ppls$Ependymal))
plot(dirichlet(ppls$`OD Mature`))
plot(dirichlet(ppls$Microglia))
``` 
-->

### Nearest Neighbour approaches

Nearest neighbour methods center around the notion of a nearness. In this section, we introduce `findKNN` from `BiocNeighbours`, a method to calculate the distances until $k$ nearest neighbours are found. This information is summarised as a histogram. In order to distill more information from this nearest-neighbour distance histogram, we follow the approach from the function `nnclean` and fit a Gamma mixture model to the data. The number of mixture components can be set individually. We choose a value of $k=2$ to model close range interactions and long range interactions. This gives us parameteric models for our histogram of nearest-neighbour distances.

```{r, cache=FALSE}
# potentially easier to just calculate the distances to a nearest neighbour and plot the hist and fit a mixture model - difficult to set the number of components in that case 
# nndistances_k5_ependymal <- nndist(ppls$Ependymal, k = 5)
# nndistances_k5_odmature <- nndist(ppls$`OD Mature`, k = 5)
# nndistances_k5_microglia <- nndist(ppls$Microglia, k = 5)
# 
# #transform the distances to sqrt and try out normalisation by intensity
# nndistances_k5_ependymal <- sqrt(nndistances_k5_ependymal)#*intensity(ppls$Ependymal)#/median(sqrt(nndistances_k5_ependymal))
# nndistances_k5_odmature <- sqrt(nndistances_k5_odmature)#*intensity(ppls$`OD Mature`)#/median(sqrt(nndistances_k5_odmature))
# nndistances_k5_microglia <- sqrt(nndistances_k5_microglia)#*intensity(ppls$Microglia)#/median(sqrt(nndistances_k5_microglia))

nndistances_k5_ependymal<-sqrt(BiocNeighbors::findKNN(as.data.frame(ppls$Ependymal), k = 15)$distance)
nndistances_k5_odmature<-sqrt(BiocNeighbors::findKNN(as.data.frame(ppls$`OD Mature`), k = 15)$distance)
nndistances_k5_microglia<-sqrt(BiocNeighbors::findKNN(as.data.frame(ppls$Microglia), k = 15)$distance)

#calculate the row Median distance of k 1-115
nndistances_ependymal_median <- rowMedians((nndistances_k5_ependymal))
nndistances_odmature_median <- rowMedians((nndistances_k5_odmature))
nndistances_microglia_median <- rowMedians((nndistances_k5_microglia))

#create a histogram of the nearest-neighbour distances
hist_ependymal <- hist(nndistances_ependymal_median, breaks = 25, plot = FALSE)
hist_odmature <- hist(nndistances_odmature_median, breaks = 25, plot = FALSE)
hist_microglia <- hist(nndistances_microglia_median, breaks = 25, plot = FALSE)

#fit now a gamma mixture model to this nndist data
gamma_mm_comp2_ependymal <- mixR::mixfit(nndistances_ependymal_median, ncomp=2,family = 'gamma')
gamma_mm_comp2_odmature <- mixR::mixfit(nndistances_odmature_median, ncomp=2,family = 'gamma')
gamma_mm_comp2_microglia <- mixR::mixfit(nndistances_microglia_median, ncomp=2,family = 'gamma')

#plot this,
c1 <- rgb(255,192,203,max = 255, alpha = 100, names = "lt.pink")
c2 <- rgb(173,216,230, max = 255, alpha = 100, names = "lt.blue")
c3 <- rgb(144,238,144, max = 255, alpha = 100, names = "lt.green")

plot(hist_ependymal, col = c1, main = "Histogram of sqrt nn-distances with Gamma Mixtures fitted",ylim=c(0,1), freq=FALSE, xlab='Median Nearest neighbour distances sqrt transformed')
legend(20,1, legend=c("Ependymal", "OD Mature", "Microglia"),col=c('red', 'blue', 'green'), lty=1, cex=0.8)
#plot the probability density of the finite mixture model
lines(density(gamma_mm_comp2_ependymal),col='red')
plot(hist_odmature, col = c2, add = TRUE, freq=FALSE)
lines(density(gamma_mm_comp2_odmature),col='blue')
plot(hist_microglia, col = c3, add = TRUE, freq=FALSE)
lines(density(gamma_mm_comp2_microglia),col='green')
```
<!-- 
```{r, cache=FALSE}
create_ridge_plot <- function(nndistances, label){
  nndistances_df <- as.data.frame(nndistances)
  nndistances_df$index <- 1:nrow(nndistances_df)
  #add the row median
  nndistances_df$median <- rowMedians((nndistances))
  nndistances_df_melted <- reshape2::melt(nndistances_df, id = 'index')
  nndistances_df_melted <-dplyr::rename(nndistances_df_melted, K = variable)
  return(ggplot(nndistances_df_melted, aes(x = value, y = K, fill=K)) + theme(legend.position="none") + ggtitle(label) + ggridges::geom_density_ridges())
}

create_ridge_plot(nndistances_k5_ependymal, label='Ependymal')
create_ridge_plot(nndistances_k5_odmature, label='OD Mature')
create_ridge_plot(nndistances_k5_microglia, label='Microglia')
``` 
-->

In the probability-density function of the nearest neighbours the ependymal cells show the shortest nearest-neighbour distances. The OD mature cells have larger nearest neighbour distances and the bimodal distribution indicates a mix of longer and wider distances (which was as well visible in the LISA $L$ function). Microglial cells show the widest distances and the symmetry of the curve indicates similar distances throughout the field of view.

### Nearest-neighbour function $G$ and empty-space function $F$

#### Definitions of $F$ and $G$ function

Under a stationary spatial point process, the empty-space distance is defined as

$$
d(u,X) = \min\{||u-x_i||: x_i \in X\}
$$

The empty space function is then the cumulative distribution function of the empty-space distances defined above

$$
F(r) = \mathbb{P}\{d(u,X)\leq r\}
$$

The nearest-neighbour distance is defined as

$$
d_i = \min_{j\neq i}||x_j-x_i||
$$

The nearest-neighbour distance distribution function $G(r)$ is then defined as

$$
G(r) = \mathbb{P}\{d(x,X\backslash u \leq r |X\ has\ a\ point\ at\ u\}
$$

For a homogeneous Poisson process, the nearest-neighbour distance distribution is identical to the empty-space function of the same process

$$
G_{pois} \equiv F_{pois}
$$

For a general point process the $F$ and $G$ functions are different

### Empty-space hazard

The $F$ and $G$ functions are, like the $K$ function, cumulative. The same disadvantages as with the $K$ function occur here too. Therefore, an analogue to the pair-correlation function would make sense to consider. For praticial reason in this case this is not the derivative of the $F$ function but rather a a hazard rate is considered

$$
h(r) = \frac{f(r)}{1-F(r)}
$$

For a completely spatially random process the hazard rate is 

$$
h_{pois}(r) = 2 \pi \lambda r
$$

Here we use a variance stabilising transformation as suggested by Baddeley et. al. This transformation means that if the process is completely spatial random, the hazard is equal to the intensity $\lambda$.
<!-- 
```{r}
fhazard_ependymal <- envelope(ppls$Ependymal, Fhazard, nsim=39, fix.n=TRUE,
transform=expression(./(2*pi*r)))
fhazard_ependymal$type <- 'Ependymal'

fhazard_odmature <- envelope(ppls$`OD Mature`, Fhazard, nsim=39, fix.n=TRUE,
transform=expression(./(2*pi*r)))
fhazard_odmature$type <- 'OD Mature'

fhazard_microglia <- envelope(ppls$Microglia, Fhazard, nsim=39, fix.n=TRUE,
transform=expression(./(2*pi*r)))
fhazard_microglia$type <- 'Microglia'

#create a list that combines bove values
fhazard_list<- rbind(fhazard_ependymal, fhazard_odmature, fhazard_microglia)

p <- ggplot(fhazard_list, aes(x=r, y=obs, col= type))+
  geom_line(key_glyph = "point")+
  guides(color = guide_legend(override.aes = list(size = 3))) +
  geom_ribbon(aes(ymin = lo, ymax = hi), alpha = 0.25, show.legend = FALSE)+
  ggtitle('Empty-space hazard')+
  geom_line(aes(x=r,y=theo),linetype = "dashed", show.legend = FALSE)+
  theme_light() + theme(legend.key.size = unit(0.5, "lines"))
p
```
 -->

### $J$-Function

The concepts of the empty-space function $F$ and the nearest-neighbour function $G$ are somewhat complementary. If one decreases, the other increases. A comparison of these two functions as a measure of CSR is the Hopkins-Skellam test (implemented above). 

Another approach is the $J$ function. 

$$
J(r) = \frac{1-G(r)}{1-F(r)}
$$

"For a homogeneous Poisson process, $F_{pois} \equiv G_{pois}$ such that then $J_{pois} \equiv 1$. Values $J(r) > 1$ are consistent with a regular pattern, and $J(r) < 1 is consistent with clustering." (Baddeley et. al.)

```{r, fig.height = 10, fig.width = 7}
G_ependymal <- Gest(ppls$Ependymal)
G_ependymal$type <- 'Ependymal'

G_odmature <- Gest(ppls$`OD Mature`)
G_odmature$type <- 'OD Mature'

G_microglia <- Gest(ppls$Microglia)
G_microglia$type <- 'Microglia'

#create a list that combines bove values
G_list<- rbind(G_ependymal, G_odmature, G_microglia)

p_G <- ggplot(G_list, aes(x=r, y=rs, col= type))+
  geom_line()+
  ggtitle('estimated G function')+
  geom_line(aes(x=r,y=theo),linetype = "dashed")+
  theme_light()

F_ependymal <- Fest(ppls$Ependymal)
F_ependymal$type <- 'Ependymal'

F_odmature <- Fest(ppls$`OD Mature`)
F_odmature$type <- 'OD Mature'

F_microglia <- Fest(ppls$Microglia)
F_microglia$type <- 'Microglia'

#create a list that combines bove values
F_list<- rbind(F_ependymal, F_odmature, F_microglia)

p_F <- ggplot(F_list, aes(x=r, y=rs, col= type))+
  geom_line()+
  ggtitle('estimated F function')+
  geom_line(aes(x=r,y=theo),linetype = "dashed")+
  theme_light()

J_ependymal <- Jest(ppls$Ependymal)
J_ependymal$type <- 'Ependymal'

J_odmature <- Jest(ppls$`OD Mature`)
J_odmature$type <- 'OD Mature'

J_microglia <- Jest(ppls$Microglia)
J_microglia$type <- 'Microglia'

#create a list that combines bove values
J_list<- rbind(J_ependymal, J_odmature, J_microglia)

p_J <- ggplot(J_list, aes(x=r, y=rs, col= type))+
  geom_line()+
  ggtitle('estimated J function')+
  geom_line(aes(x=r,y=theo),linetype = "dashed", col='black')+
  theme_light()
``` 

```{r, cache=FALSE, fig.height = 10, fig.width = 7}
p_G/p_F/p_J
```

### Accounting for Inhomogeneity in Spacing Functions

There are inhomogeneous variants of the spacing functions explained above 

```{r}
G_inhom_ependymal <- Ginhom(ppls$Ependymal)
G_inhom_ependymal$type <- 'Ependymal'

G_inhom_odmature <- Ginhom(ppls$`OD Mature`)
G_inhom_odmature$type <- 'OD Mature'

G_inhom_microglia <- Ginhom(ppls$Microglia)
G_inhom_microglia$type <- 'Microglia'

#create a list that combines bove values
G_inhom_list<- rbind(G_inhom_ependymal, G_inhom_odmature, G_inhom_microglia)

p_G <- ggplot(G_inhom_list, aes(x=r, y=bord, col= type))+
  geom_line()+
  ggtitle('estimated inhomogneous G function')+
  geom_line(aes(x=r,y=theo),linetype = "dashed")+
  theme_light()

F_inhom_ependymal <- Finhom(ppls$Ependymal)
F_inhom_ependymal$type <- 'Ependymal'

F_inhom_odmature <- Finhom(ppls$`OD Mature`)
F_inhom_odmature$type <- 'OD Mature'

F_inhom_microglia <- Finhom(ppls$Microglia)
F_inhom_microglia$type <- 'Microglia'

#create a list that combines bove values
F_inhom_list<- rbind(F_inhom_ependymal, F_inhom_odmature, F_inhom_microglia)

p_F <- ggplot(F_inhom_list, aes(x=r, y=bord, col= type))+
  geom_line()+
  ggtitle('estimated inhomogneous F function')+
  geom_line(aes(x=r,y=theo),linetype = "dashed")+
  theme_light()

J_inhom_ependymal <- Jinhom(ppls$Ependymal)
J_inhom_ependymal$type <- 'Ependymal'

J_inhom_odmature <- Jinhom(ppls$`OD Mature`)
J_inhom_odmature$type <- 'OD Mature'

J_inhom_microglia <- Jinhom(ppls$Microglia)
J_inhom_microglia$type <- 'Microglia'

#create a list that combines bove values
J_inhom_list<- rbind(J_inhom_ependymal, J_inhom_odmature, J_inhom_microglia)

p_J <- ggplot(J_inhom_list, aes(x=r, y=bord, col= type))+
  geom_line()+
  ggtitle('estimated inhomogneous J function')+
  geom_line(aes(x=r,y=theo),linetype = "dashed", col='black')+
  theme_light()
```

```{r, cache=FALSE, fig.height = 10, fig.width = 7}
p_G/p_F/p_J
```

Again here, comparing the homogeneous versions of the functions with the inhomogeneous ones reveals, that we seem to solve one problem (inhomogeneity) by assuming correlation stationarity. As this is not given, the inhomogeneous versions don't seem to be accurate. In fact, the homogeneous versions are more easily interpretable than the inhomogeneous alternatives.

### Nearest-Neighbour Orientation

Next to the distance to the nearest-neighbour we can estimate the orientation of the vector to the nearest-neighbour. This gives an indication of the orientation of the spacing.

```{r}
nnorient_ependymal <- nnorient(ppls$Ependymal)
nnorient_ependymal$type <- 'Ependymal'

nnorient_odmature <- nnorient(ppls$`OD Mature`)
nnorient_odmature$type <- 'OD Mature'

nnorient_microglia <- nnorient(ppls$Microglia)
nnorient_microglia$type <- 'Microglia'

#create a list that combines bove values
nnorient_list<- rbind(nnorient_ependymal, nnorient_odmature, nnorient_microglia)

p <- ggplot(nnorient_list, aes(x=phi, y=bordm, col= type))+
  geom_line()+
  ggtitle('Nearest-neighbour orientation function')+
  geom_line(aes(x=phi,y=theo),linetype = "dashed", col = 'black')+
  theme_light()
p
```

The same can be portrayed as a rose diagram

```{r}
rose(nnorient_ependymal)
rose(nnorient_odmature)
rose(nnorient_microglia)
```

We see that the orientation of the Ependymal nearest-neighbours is along the vertical axis, OD mature cells don't show a clear pattern and microglial cells a horizontal orientation in their nearest neighbours.

The concept of spacing is not only usable in point pattern analysis but more broadly in any spatial context (e.g. spacing between shapes instead of points).

### Edge Corrections

The same consideration about edge effects as for the $K$ functions have to be made for the spacing functions. The uncorrected estimators are negatively biased as estimators for the real spacing functions. The easiest approach is to draw an artificial border and consider nearest neighbours there in. Other approaches are based on sampling. Yet another approach is based on survival analysis. The idea is that a circle of a point to grows homogeneously with increasing radius until it hits the frame of the window and "dies". This gives survival distributions. This is similar to censored data, where the Kaplan-Meier estimator is the optimal choice. 

# Appendix

## Session info 

```{r, cache=FALSE}
#| label: session-info
sessionInfo()
```
